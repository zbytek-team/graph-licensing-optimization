\chapter{Dodatek}\label{chap:appendix}

\section{Architektura implementacji}

\subsection{Struktura projektu}

Implementacja systemu \texttt{glopt} (Graph Licensing Optimization) została zorganizowana jako modularny pakiet Python 3.13 z następującą strukturą katalogów:

\begin{verbatim}
src/glopt/                    # Pakiet główny
├── __init__.py              # Interfejs publiczny
├── algorithms/              # Implementacje algorytmów
│   ├── ilp.py              # Programowanie całkowitoliczbowe
│   ├── ant_colony.py       # Algorytm mrówkowy (ACO)
│   ├── genetic.py          # Algorytm genetyczny
│   ├── simulated_annealing.py # Wyżarzanie symulowane
│   ├── tabu_search.py      # Przeszukiwanie tabu
│   ├── greedy.py           # Heurystyka zachłanna
│   ├── dominating_set.py   # Zbiór dominujący
│   ├── tree_dp.py          # Programowanie dynamiczne dla drzew
│   ├── randomized.py       # Baseline losowy
│   └── naive.py            # Rozwiązanie naiwne
├── core/                    # Modele podstawowe i logika
│   ├── models.py           # Typy licencji, rozwiązania
│   ├── solution_builder.py # Konstruktor rozwiązań
│   ├── run.py              # Wykonanie pojedynczego algorytmu
│   └── mutations.py        # Operatory mutacji dla GA
├── io/                      # Wejście/wyjście danych
│   ├── csv_writer.py       # Eksport wyników CSV
│   ├── data_loader.py      # Ładowanie sieci ego Facebook
│   ├── graph_generator.py  # Generatory grafów syntetycznych
│   └── graph_visualizer.py # Wizualizacja grafów
├── cli/                     # Interfejs linii poleceń
│   ├── benchmark.py        # Benchmark statyczny
│   ├── dynamic.py          # Benchmark dynamiczny
│   ├── pipelines.py        # Pipeline'y eksperymentalne
│   └── trees.py            # Testy na drzewach
├── utils/                   # Narzędzia pomocnicze
│   └── runtime.py          # Wymuszenie Python 3.13
├── license_config.py        # Konfiguracje licencyjne
└── dynamic_simulator.py     # Symulator dynamiczny

scripts/analysis/            # Analiza wyników
└── analysis/               # Moduły analizy danych
    ├── main.py             # Główny punkt wejścia
    ├── plots_*.py          # Generatory wykresów
    ├── tables_*.py         # Generatory tabel
    └── stats_tests.py      # Testy statystyczne

data/                        # Dane wejściowe
├── facebook/               # Sieci ego z Facebook
└── graphs_cache/           # Cache grafów syntetycznych

runs/                        # Wyniki eksperymentów
└── <run_id>/               # Katalog pojedynczego uruchomienia
    ├── csv/                # Dane surowe CSV
    └── analysis/           # Wykresy i tabele
\end{verbatim}

\subsection{Kluczowe abstrakcje}

\subsubsection{Typ licencji}

Podstawowy model licencji jest reprezentowany przez klasę \texttt{LicenseType}:

\begin{verbatim}
@dataclass(frozen=True, slots=True)
class LicenseType:
    name: str                # Nazwa licencji
    cost: float             # Koszt licencji
    min_capacity: int       # Minimalna pojemność
    max_capacity: int       # Maksymalna pojemność
    color: str             # Kolor do wizualizacji
\end{verbatim}

\subsubsection{Grupa licencyjna}

Grupa użytkowników korzystających ze wspólnej licencji:

\begin{verbatim}
@dataclass(frozen=True, slots=True)
class LicenseGroup:
    license_type: LicenseType    # Typ licencji
    members: frozenset[N]        # Zbiór członków grupy
    owner: N                     # Właściciel licencji
\end{verbatim}

\subsubsection{Rozwiązanie}

Kompletny podział użytkowników na grupy licencyjne:

\begin{verbatim}
@dataclass(frozen=True, slots=True)
class Solution:
    graph: nx.Graph[N]           # Graf sieci społecznej
    groups: frozenset[LicenseGroup[N]]  # Grupy licencyjne
    total_cost: float            # Łączny koszt
\end{verbatim}

\section{Konfiguracje licencyjne}

\subsection{Konfiguracje rzeczywiste}

System implementuje następujące konfiguracje licencyjne odpowiadające rzeczywistym usługom:

\subsubsection{Duolingo Super}
\begin{itemize}
\item \textbf{Individual}: koszt \$13.99, pojemność 1
\item \textbf{Family}: koszt \$29.17, pojemność 2--6
\end{itemize}

\subsubsection{Spotify}
\begin{itemize}
\item \textbf{Individual}: koszt \$23.99, pojemność 1
\item \textbf{Duo}: koszt \$30.99, pojemność 2
\item \textbf{Family}: koszt \$37.99, pojemność 2--6
\end{itemize}

\subsubsection{Netflix}
\begin{itemize}
\item \textbf{StandardWithAds}: koszt \$7.99, pojemność 1
\item \textbf{Standard}: koszt \$17.99, pojemność 2
\item \textbf{Premium}: koszt \$24.99, pojemność 2--4
\end{itemize}

\subsection{Konfiguracje teoretyczne}

\subsubsection{Dominowanie rzymskie}
\begin{itemize}
\item \textbf{Solo}: koszt 1.0, pojemność 1
\item \textbf{Group}: koszt 2.0, pojemność 2--$\infty$
\end{itemize}

\subsubsection{Parametryczne warianty}

System obsługuje parametryczne konfiguracje umożliwiające analizę wrażliwości na ceny:

\begin{itemize}
\item \texttt{roman\_p\_X\_Y}: wariant dominowania rzymskiego z kosztem grupy $X.Y$
\item \texttt{duolingo\_p\_X\_Y}: wariant Duolingo z kosztem rodzinnym $X.Y \times$ koszt indywidualny
\end{itemize}

Przykłady: \texttt{roman\_p\_1\_5} (koszt grupy = 1.5), \texttt{duolingo\_p\_2\_5} (koszt rodzinny = 2.5$\times$ indywidualny).

\section{Szczegóły implementacji algorytmów}

\subsection{Programowanie całkowitoliczbowe (ILPSolver)}

Implementacja wykorzystuje bibliotekę PuLP z solverem domyślnym (CBC). Model matematyczny:

\begin{verbatim}
Variables:
  x[v,t] ∈ {0,1}     # użytkownik v ma licencję typu t
  y[v,u,t] ∈ {0,1}   # v jest w grupie właściciela u typu t
  z[v,t] ∈ {0,1}     # v jest właścicielem licencji typu t

Constraints:
  ∀v: ∑_t x[v,t] = 1                    # każdy ma dokładnie jedną licencję
  ∀v,t: x[v,t] ≤ z[v,t] + ∑_{u∈N(v)} y[v,u,t]  # pokrycie
  ∀v,u,t: y[v,u,t] ≤ x[u,t]            # właściciel musi mieć licencję
  ∀u,t: ∑_{v∈N(u)∪{u}} y[v,u,t] ≤ K_t × x[u,t]  # pojemność

Objective: minimize ∑_{v,t} c_t × z[v,t]
\end{verbatim}

\subsection{Algorytm mrówkowy (AntColonyOptimization)}

Parametry domyślne:
\begin{itemize}
\item Liczba mrówek: $\min(20, |V|)$
\item Liczba iteracji: 100
\item Współczynnik odparowania: $\rho = 0.1$
\item Względna waga feromonów: $\alpha = 1.0$
\item Względna waga heurystyki: $\beta = 2.0$
\item Prawdopodobieństwo wyboru najlepszego: $q_0 = 0.1$
\end{itemize}

Heurystyka lokalnej: $\eta_{v,t} = \frac{1}{c_t \cdot \max(1, |N(v)| - K_t + 1)}$

\subsection{Algorytm genetyczny (GeneticAlgorithm)}

Parametry domyślne:
\begin{itemize}
\item Rozmiar populacji: 50
\item Liczba generacji: 200
\item Prawdopodobieństwo krzyżowania: 0.8
\item Prawdopodobieństwo mutacji: 0.2
\item Rozmiar turnieju: 3
\end{itemize}

Operatory mutacji:
\begin{itemize}
\item \texttt{FLIP\_RANDOM}: zmiana losowego węzła na losowy typ licencji
\item \texttt{FLIP\_NEIGHBOR}: zmiana losowego węzła na typ sąsiada
\item \texttt{MERGE\_GROUPS}: połączenie dwóch grup tego samego typu
\item \texttt{SPLIT\_GROUP}: podział grupy na mniejsze
\end{itemize}

\subsection{Wyżarzanie symulowane (SimulatedAnnealing)}

Parametry domyślne:
\begin{itemize}
\item Temperatura początkowa: $T_0 = 100.0$
\item Temperatura końcowa: $T_{\text{min}} = 0.01$
\item Współczynnik chłodzenia: $\alpha = 0.95$
\item Długość epoki: $\max(100, |V|)$
\end{itemize}

Schedule chłodzenia: $T_{k+1} = \alpha \cdot T_k$

\subsection{Przeszukiwanie tabu (TabuSearch)}

Parametry domyślne:
\begin{itemize}
\item Rozmiar listy tabu: $\max(10, |V|/10)$
\item Maksymalna liczba iteracji: 1000
\item Maksymalna liczba iteracji bez poprawy: 100
\item Intensywność dywersyfikacji: co 200 iteracji
\end{itemize}

\section{Generatory grafów syntetycznych}

System implementuje następujące generatory grafów do testów:

\subsection{Graf losowy (Erdős-Rényi)}
\begin{verbatim}
G(n, p) gdzie:
- n: liczba węzłów
- p: prawdopodobieństwo krawędzi między każdą parą węzłów
\end{verbatim}

\subsection{Graf bezskalowy (Barabási-Albert)}
\begin{verbatim}
BA(n, m) gdzie:
- n: liczba węzłów
- m: liczba krawędzi dodawanych z każdym nowym węzłem
\end{verbatim}

\subsection{Graf małoświatowy (Watts-Strogatz)}
\begin{verbatim}
WS(n, k, p) gdzie:
- n: liczba węzłów
- k: stopień każdego węzła w grafie regularnym
- p: prawdopodobieństwo przeprojektowania krawędzi
\end{verbatim}

\subsection{Parametry eksperymentalne}

Standardowe rozmiary grafów: $n \in \{20, 50, 100, 200, 500\}$

Parametry generatorów:
\begin{itemize}
\item Random: $p = 0.15$
\item Barabási-Albert: $m = 2$
\item Watts-Strogatz: $k = 4$, $p = 0.3$
\end{itemize}

Próbki na rozmiar: 10, powtórzeń na graf: 3

\section{Dane rzeczywiste}

\subsection{Sieci ego Facebook}

Wykorzystano zbiór danych Stanford SNAP zawierający sieci ego z Facebook:

\begin{itemize}
\item Liczba sieci ego: 10 (ID: 0, 107, 348, 414, 686, 698, 1684, 1912, 3437, 3980)
\item Rozmiary: od 166 węzłów (ego 1912) do 4039 węzłów (ego 0)
\item Średni stopień: 20--50 w zależności od sieci
\item Współczynnik klastrowania: 0.1--0.3
\end{itemize}

Format danych:
\begin{itemize}
\item \texttt{<id>.edges}: lista krawędzi (bez ego)
\item \texttt{<id>.circles}: okręgi społeczne (nieużywane w tej pracy)
\item \texttt{<id>.feat}, \texttt{<id>.featnames}: cechy węzłów (nieużywane)
\end{itemize}

\subsection{Preprocessing}

Automatyczne dodanie węzła ego i połączenie ze wszystkimi węzłami w sieci, zgodnie z definicją sieci ego.

\section{Format wyników}

\subsection{Struktura CSV}

Każdy eksperyment generuje plik CSV z następującymi kolumnami:

\begin{verbatim}
run_id              # Identyfikator uruchomienia
algorithm           # Nazwa algorytmu
graph              # Typ grafu (random/barabasi/watts/ego)
n_nodes            # Liczba węzłów
n_edges            # Liczba krawędzi
graph_params       # Parametry generatora (JSON)
license_config     # Konfiguracja licencyjna
cost               # Koszt rozwiązania
execution_time     # Czas wykonania (sekundy)
groups_count       # Liczba grup w rozwiązaniu
individual_count   # Liczba licencji indywidualnych
family_count       # Liczba licencji rodzinnych
duo_count          # Liczba licencji duo (jeśli dotyczy)
timeout            # Czy wystąpił timeout (bool)
seed               # Ziarno losowości
rep                # Numer powtórzenia
sample             # Numer próbki
\end{verbatim}

\subsection{Struktura katalogów wyników}

\begin{verbatim}
runs/<timestamp>_<suffix>/
├── csv/
│   └── <timestamp>_<suffix>.csv  # Dane surowe
├── analysis/                      # Wygenerowane przez make analyze
│   ├── plots/                    # Wykresy (PNG/PDF)
│   ├── tables/                   # Tabele LaTeX
│   └── summary.txt               # Podsumowanie tekstowe
└── glopt.log                     # Logi debugowe
\end{verbatim}

\section{Instrukcje reprodukcji}

\subsection{Wymagania systemowe}

\begin{itemize}
\item Python 3.13 (wymagana dokładna wersja)
\item \texttt{uv} jako menedżer środowiska (https://github.com/astral-sh/uv)
\item Co najmniej 4 GB RAM dla większych eksperymentów
\item System operacyjny: Linux, macOS, Windows z WSL
\end{itemize}

\subsection{Instalacja}

\begin{verbatim}
# Klonowanie repozytorium
git clone <url> glopt
cd glopt

# Instalacja środowiska i zależności
make install
\end{verbatim}

\subsection{Uruchomienie eksperymentów}

\begin{verbatim}
# Benchmark statyczny (grafy syntetyczne)
make benchmark

# Benchmark na danych rzeczywistych
make benchmark_real

# Analiza dynamiczna
make dynamic

# Analiza wyników (wykresy, tabele)
make analyze

# Kompilacja pracy (wymaga LaTeX/tectonic)
make thesis
\end{verbatim}

\subsection{Konfiguracja eksperymentów}

Parametry eksperymentalne można modyfikować w plikach:
\begin{itemize}
\item \texttt{src/glopt/cli/benchmark.py}: rozmiary grafów, liczba powtórzeń, timeout
\item \texttt{src/glopt/cli/dynamic.py}: parametry symulacji dynamicznej
\item \texttt{src/glopt/license\_config.py}: konfiguracje licencyjne
\end{itemize}

Główne parametry (domyślne wartości):
\begin{verbatim}
SIZES = [20, 50, 100, 200, 500]        # Rozmiary grafów
SAMPLES_PER_SIZE = 10                  # Próbek na rozmiar
REPEATS_PER_GRAPH = 3                  # Powtórzeń na graf
TIMEOUT_SECONDS = 60.0                 # Timeout algorytmu
\end{verbatim}

\subsection{Analiza wyników}

System analizy wyników składa się z modułów w \texttt{scripts/analysis/}:

\begin{itemize}
\item \texttt{plots\_cost\_time.py}: wykresy koszt vs. czas
\item \texttt{plots\_pareto.py}: fronty Pareto
\item \texttt{tables\_aggregates.py}: tabele średnich wyników
\item \texttt{stats\_tests.py}: testy statystyczne (Wilcoxon, Friedman)
\end{itemize}

Uruchomienie: \texttt{make analyze} (wymaga poprawnego pliku CSV w \texttt{runs/})

\section{Parametry metaheurystyk}

\subsection{Tabela wszystkich parametrów}

\begin{table}[h!]
\centering
\caption{Parametry domyślne metaheurystyk}
\begin{tabular}{|l|l|c|}
\hline
\textbf{Algorytm} & \textbf{Parametr} & \textbf{Wartość} \\
\hline
\multirow{6}{*}{ACO} & Liczba mrówek & $\min(20, |V|)$ \\
& Iteracje & 100 \\
& Odparowanie ($\rho$) & 0.1 \\
& Waga feromonów ($\alpha$) & 1.0 \\
& Waga heurystyki ($\beta$) & 2.0 \\
& Próg najlepszego ($q_0$) & 0.1 \\
\hline
\multirow{5}{*}{GA} & Rozmiar populacji & 50 \\
& Generacje & 200 \\
& P. krzyżowania & 0.8 \\
& P. mutacji & 0.2 \\
& Rozmiar turnieju & 3 \\
\hline
\multirow{4}{*}{SA} & Temp. początkowa & 100.0 \\
& Temp. końcowa & 0.01 \\
& Wsp. chłodzenia & 0.95 \\
& Długość epoki & $\max(100, |V|)$ \\
\hline
\multirow{4}{*}{Tabu} & Rozmiar listy tabu & $\max(10, |V|/10)$ \\
& Maks. iteracji & 1000 \\
& Iteracje bez poprawy & 100 \\
& Dywersyfikacja & co 200 iter. \\
\hline
\end{tabular}
\end{table}

\subsection{Uzasadnienie wyboru parametrów}

Parametry zostały dobrane na podstawie literatury oraz wstępnych testów pilotażowych:

\begin{itemize}
\item \textbf{ACO}: Liczba mrówek ograniczona rozmiarem problemu, parametry $\alpha$, $\beta$ zgodne z Dorigo \& Stützle (2004)
\item \textbf{GA}: Klasyczne wartości z literatury algorytmów genetycznych (Goldberg, 1989)
\item \textbf{SA}: Schedule wykładniczy z temperaturą dostosowaną do zakresu kosztów
\item \textbf{Tabu}: Rozmiar listy tabu proporcjonalny do rozmiaru problemu
\end{itemize}

Wszystkie metaheurystyki wykorzystują wspólny mechanizm generowania sąsiedztwa oparty na operatorach mutacji z algorytmu genetycznego.
