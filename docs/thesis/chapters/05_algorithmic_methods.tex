\chapter{Metody algorytmiczne}\label{chap:algorithms}

W rozdziale przedstawiono algorytmy zastosowane w pracy. Każdy algorytm opisano, podając ideę, parametry oraz analizę złożoności obliczeniowej.


Algorytmy zastosowane w pracy dzielą się na trzy grupy:
\begin{enumerate}
  \item \textbf{Metody dokładne} -- gwarantują znalezienie optymalnego rozwiązania: algorytm naiwny i programowanie całkowitoliczbowe (ILP).
  \item \textbf{Heurystyki konstrukcyjne} -- metody konstruujące rozwiązanie sekwencyjnie: algorytm zachłanny, heurystyka oparta na zbiorze dominującym, algorytm losowy.
  \item \textbf{Metaheurystyki} -- metody przeszukujące przestrzeń rozwiązań w sposób systematyczny: algorytm genetyczny, przeszukiwanie tabu, algorytm mrówkowy, symulowane wyżarzanie.
\end{enumerate}

\section{Metody dokładne}

\subsection{Algorytm naiwny}\label{subsec:naive}
Algorytm naiwny jest metodą dokładną. Przegląda wszystkie podziały zbioru wierzchołków na dopuszczalne grupy oraz wszystkie przypisania licencji. Wybierane jest rozwiązanie o najniższym koszcie. Liczba rozważanych konfiguracji rośnie wykładniczo, dlatego metoda ma znaczenie praktyczne tylko dla bardzo małych instancji.

Na rysunku \ref{fig:all_types_time} przedstawiono czasy obliczeń w funkcji liczby wierzchołków dla grafów losowych, małoświatowych i bezskalowych. Dla $n\le 12$ czas wykonania jest akceptowalny w eksperymentach. Ze względu na wykładniczy wzrost czasu działania metoda staje się niepraktyczna dla większych instancji, w szczególności wobec dostępności wydajniejszych metod, takich jak programowanie całkowitoliczbowe (ILP).

\begin{figure}[H]
  \centering
  \includegraphics[width=0.66\textwidth]{assets/all_types_plot.png}
  \caption{Czas obliczeń algorytmu naiwnego w funkcji liczby wierzchołków $n$ dla trzech typów grafów}
  \label{fig:all_types_time}
\end{figure}

\paragraph{Opis metody}
\begin{enumerate}
  \item Wygenerować wszystkie partycje zbioru \(V\) na niepuste zestawy (każdy zestaw odpowiada kandydatowi na grupę licencyjną).
  \item Dla każdego zestawu w danej partycji wyznaczyć wszystkie dopuszczalne pary (właściciel, licencja), czyli takie, które spełniają ograniczenia pojemności oraz sąsiedztwa.
  \item Złożyć wybory z poszczególnych zestawów w pełne przypisania i odrzucić konfiguracje, które nie pokrywają wierzchołków lub łamią ograniczenia.
  \item Obliczyć koszt na podstawie funkcji kosztu $\cost(f)$ (\ref{eq:cost_function}) i zaktualizować najlepsze rozwiązanie.
\end{enumerate}

\begin{algorithm}[H]
  \caption{Algorytm naiwny: pełny przegląd rozwiązań}
  \label{alg:naive}
  \begin{algorithmic}[1]
    \Require graf \(G=(V,E)\), zbiór typów licencji \(L\)
    \If{\(|V|>12\)} \State \Return zakończenie działania z powodu ograniczenia eksperymentalnego \EndIf
    \State \(best\_cost \gets \infty\), \(best \gets \emptyset\)
    \For{każda partycja \(P=\{P_1,\dots,P_k\}\) zbioru \(V\)}
    \For{każde przypisanie \(l_t\in L\) i właściciela w każdym \(P_i\)}
    \If{spełnione są ograniczenia pojemności, sąsiedztwa i pokrycia}
    \State oblicz koszt; zaktualizuj \(best\), jeśli lepszy
    \EndIf
    \EndFor
    \EndFor
    \State \Return \(best\)
  \end{algorithmic}
\end{algorithm}

\paragraph{Złożoność}
Algorytm generuje wszystkie partycje zbioru \(V\) na niepuste zestawy, czyli wszystkie rozbicia odpowiadające potencjalnym zestawom grup licencyjnych. Takich partycji jest \(B_{|V|}\), gdzie \(B_m\) oznacza liczbę Bella dla \(m\) elementów \cite{stanley1997enumerative}. W implementacji nie ograniczono z góry liczby zestawów: niektóre typy licencji mogą pozostać nieużyte, dlatego dopuszczamy zarówno rozbicia na jedną grupę, jak i na \(|V|\) grup jednowierzchołkowych. Gdyby liczba zestawów była stała i wynosiła \(k\), odpowiadałyby jej liczby Stirlinga drugiego rodzaju \({|V| \brace k}\); tutaj sumujemy je po wszystkich \(k\), stąd pojawiają się liczby Bella. Samo wygenerowanie partycji ma koszt $\Theta(B_{|V|})$.

Dla partycji o \(k\) zestawach o rozmiarach \(s_1, s_2, \ldots, s_k\) rozpatrujemy każdą kombinację wyboru właściciela (co najwyżej \(s_i\) opcji na zestaw \(i\)) i dopuszczalnego typu licencji (co najwyżej \(T\) opcji, gdzie \(T=|L|\)). Prowadzi to do górnego oszacowania
\[
  \prod_{i=1}^{k} (s_i \cdot T) = T^k \cdot \prod_{i=1}^{k} s_i
\]
konfiguracji dla pojedynczej partycji. Całkowity koszt można oszacować przez \(O\bigl(B_{|V|} \cdot T^{|V|} \cdot 3^{|V|/3}\bigr)\), ponieważ \(\prod s_i \leq 3^{|V|/3}\). Wzrost jest superwykładniczy, gdzie asymptotycznie \(\log B_n = n\log n - n\log\log n - n + O(n/\log n)\). W praktyce ograniczenia licencyjne i warunek sąsiedztwa znacząco zmniejszają liczbę rozważanych konfiguracji, lecz nawet wtedy pełny przegląd jest użyteczny wyłącznie dla bardzo małych grafów (rzędu kilku do kilkunastu wierzchołków).

Liczby Bella można zapisać wzorami
\[
  B_n = \sum_{k=0}^{n} \left\{\!\!\begin{array}{c} n \\ k \end{array}\!\!\right\}\quad\text{oraz}\quad B_n = \frac{1}{e}\sum_{k=0}^{\infty}\frac{k^{\,n}}{k!},
\]
a zliczają one wszystkie rozbiory zbioru na dowolną liczbę niepustych zestawów (zestawy są nierozróżnialne). Dla porównania liczba wszystkich podzbiorów zbioru \(n\)-elementowego wynosi jedynie \(2^n\), więc nawet tak uproszczone oszacowanie rośnie wolniej niż pełna liczba partycji.

\subsection{Programowanie całkowitoliczbowe (ILP)}\label{subsec:ilp}

Problem z rozdziału~\ref{sec:model-formal} formułujemy jako minimalizację kosztu przy ograniczeniach liniowych z binarnymi zmiennymi. Model jest dokładny. Algorytm zwraca rozwiązanie optymalne, jeśli solver zakończy działanie ze statusem \texttt{Optimal}. W przypadku statusu \texttt{Infeasible}, \texttt{Unbounded} lub \texttt{Not Solved} zwracane jest rozwiązanie zapasowe z licencjami indywidualnymi.

\paragraph{Parametry i zmienne}
Korzystamy z rodziny licencji z~\eqref{eq:license_family},
\(L=\{l_t=(c_t,m_t,k_t):t=1,\dots,T\}\).
Oznaczamy \(N[i]=N(i)\cup\{i\}\). Dla \(i\in V\), \(t\in\{1,\dots,T\}\) definiujemy:
\begin{itemize}
  \item \(a_{i,t}\in\{0,1\}\): \(a_{i,t}=1\) gdy węzeł \(i\) staje się właścicielem grupy licencyjnej typu \(t\). Właściciel kupuje licencję i dzieli jej korzyści z wybranymi sąsiadami zgodnie z ograniczeniami pojemności \(m_t \leq |grupa| \leq k_t\). Właściciel zawsze należy do własnej grupy.
  \item \(x_{i,j,t}\in\{0,1\}\) dla \(j\in N[i]\): \(x_{i,j,t}=1\) gdy \(j\) należy do grupy właściciela \(i\) typu \(t\).
\end{itemize}
Zmienna \(x_{i,j,t}\) odwzorowuje przypisanie odbiorcy do właściciela; zbiory ról są indukowane przez wartości \((a,x)\).

\paragraph{Model}
\begin{align}
  \min\quad & \sum_{i\in V}\sum_{t=1}^{T} c_t\, a_{i,t}                                                                        \\
  \text{pod warunkami:}\quad
            & \sum_{i\in N[j]}\sum_{t=1}^{T} x_{i,j,t} = 1
            &                                                                & \forall j\in V \label{con:cover}                \\
            & m_t\, a_{i,t} \le \sum_{j\in N[i]} x_{i,j,t} \le k_t\, a_{i,t}
            &                                                                & \forall i\in V,\ \forall t \label{con:capacity} \\
            & x_{i,i,t} = a_{i,t}
            &                                                                & \forall i\in V,\ \forall t \label{con:owner}    \\
            & \sum_{t=1}^{T} a_{i,t} \le 1
            &                                                                & \forall i\in V \label{con:one}
\end{align}

Znaczenie ograniczeń: \eqref{con:cover} wymusza jednokrotne pokrycie każdego węzła; \eqref{con:capacity} wymusza przedziały wielkości grup; \eqref{con:owner} zapewnia udział właściciela; \eqref{con:one} ogranicza do jednej licencji na węzeł (dowolnego typu). Ograniczenia pokrywają warunki wykonalności z rozdziału~\ref{sec:model-formal}.

\paragraph{Złożoność}
Liczba zmiennych: \(|V|T\) dla \(a_{i,t}\) oraz \(T\sum_i |N[i]|\) dla \(x_{i,j,t}\), łącznie \(O\!\bigl(T(|E|+|V|)\bigr)\).
Liczba ograniczeń: \(|V|\) dla \eqref{con:cover}, \(2|V|T\) dla \eqref{con:capacity}, \(|V|T\) dla \eqref{con:owner}, \(|V|\) dla \eqref{con:one}.
Model służy jako punkt odniesienia dla instancji małych i średnich.

Problemem ILP jest wykładnicza złożoność czasowa w najgorszym przypadku. Alternatywnym podejściem jest \emph{relaksacja liniowa}, gdzie zmienne binarne zastąpiono ciągłymi z przedziałem \([0,1]\), co daje wielomianowy czas rozwiązania. Rozwiązanie relaksacji stanowi dolne oszacowanie optimum, ale wymaga zaokrąglenia i może naruszać ograniczenia. W niniejszej pracy zastosowano dokładne rozwiązanie binarne ILP.

\paragraph{Implementacja}
Implementacja w Pythonie (PuLP+CBC) odzwierciedla model. Stosuje się eliminację niemożliwych par \((i,t)\), gdy \(m_t>|N[i]|\) lub \(k_t<1\), oraz dla \(k_t=1\) tworza się wyłącznie zmienne \(x_{i,i,t}\).
Wszystkie zmienne decyzyjne są zdefiniowane jako binarne (\texttt{cat="Binary"}).
W przypadku statusu innego niż \texttt{Optimal} zwracane jest rozwiązanie zapasowe, w którym wszystkim węzłom przypisano najtańsze dostępne licencje indywidualne.

\section{Heurystyki konstrukcyjne}

Heurystyki konstrukcyjne budują rozwiązanie sekwencyjnie, w każdym kroku podejmując decyzje na podstawie lokalnych kryteriów. Metody te charakteryzują się szybkim czasem działania, ale nie gwarantują znalezienia rozwiązania optymalnego. W tej grupie znajdują się algorytm zachłanny, heurystyka oparta na zbiorze dominującym oraz algorytm losowy wykorzystywany jako punkt odniesienia.

\subsection{Algorytm zachłanny}\label{subsec:greedy}

Algorytm zachłanny to szybka heurystyka, która buduje rozwiązanie krok po kroku, w każdym kroku wybierając lokalnie najlepszą opcję. Algorytm nie gwarantuje znalezienia optymalnego rozwiązania, ale jest bardzo szybki i daje zazwyczaj w miarę dobre wyniki.

\paragraph{Opis metody}
Algorytm działa według następującej strategii:
\begin{enumerate}
  \item Sortuje wierzchołki nierosnąco według liczby sąsiadów (stopnia wierzchołka).
  \item Dla każdego wierzchołka sprawdza, czy może być właścicielem grupy.
  \item Wybiera typ licencji i rozmiar grupy tak, aby zminimalizować stosunek kosztu do rozmiaru grupy.
  \item Dodaje członków do grupy wybierając wierzchołki o największej liczbie sąsiadów.
  \item Powtarza proces dla wszystkich niepokrytych wierzchołków.
\end{enumerate}

Algorytm nie wymaga strojenia parametrów. Wszystkie decyzje są podejmowane deterministycznie na podstawie struktury grafu i kosztów licencji, choć w przypadku wierzchołków o tym samym stopniu kolejność wyboru może wpływać na wynik końcowy.

Sortowanie według stopnia wierzchołka (liczby sąsiadów) sprawdza się dobrze w praktyce, ponieważ wierzchołki o wysokim stopniu mogą tworzyć większe, bardziej efektywne grupy licencyjne.

\begin{algorithm}[H]
  \caption{Algorytm zachłanny}
  \label{alg:greedy}
  \begin{algorithmic}[1]
    \Require graf $G=(V,E)$, zbiór typów licencji $L$
    \State posortuj wierzchołki nierosnąco według stopnia
    \State $niepokryte \gets V$
    \For{każdy wierzchołek $v$ w posortowanej kolejności}
    \If{$v$ już pokryty} \textbf{continue} \EndIf
    \State znajdź dostępnych sąsiadów $v$ wśród niepokrytych
    \For{każdy typ licencji $l_t \in L$}
    \State oblicz efektywność: $koszt_{l_t} / rozmiar\_grupy$
    \EndFor
    \State wybierz licencję i członków grupy o najlepszej efektywności
    \State utwórz grupę z $v$ jako właścicielem
    \State usuń członków grupy z $niepokryte$
    \EndFor
    \State \Return utworzone grupy
  \end{algorithmic}
\end{algorithm}


\paragraph{Złożoność i zastosowanie}
Algorytm ma złożoność czasową $O(|V|\,T + |E|\log |V|)$, gdzie $|V|$ to liczba wierzchołków, $|E|$ to liczba krawędzi, a $T$ to liczba typów licencji.
Algorytm zachłanny jest bardzo szybki i daje stabilne wyniki. Z tego powodu często używany był jako:
\begin{itemize}
  \item podstawowa metoda do porównywania z innymi algorytmami,
  \item źródło rozwiązania początkowego dla bardziej zaawansowanych metod,
  \item szybka metoda dla dużych grafów, gdzie inne algorytmy są zbyt wolne.
\end{itemize}
Wadą algorytmu jest ryzyko pominięcia rozwiązań globalnie lepszych wskutek lokalnych decyzji.
\subsection{Heurystyka zbioru dominującego}\label{subsec:ds}

Heurystyka korzysta z \emph{minimalnych względem inkluzji} zbiorów dominujących. Zbiór dominujący jest minimalny, gdy usunięcie dowolnego jego wierzchołka powoduje utratę własności dominowania \cite{haynes1998domination}. W kontekście licencjonowania dominatorem nazywa się wierzchołek wybrany do zbioru dominującego, który stanie się właścicielem grupy licencyjnej i pokryje siebie oraz swoich sąsiadów. Dla przejrzystości wprowadzamy zbiór $F$ oznaczający wierzchołki, które nie zostały jeszcze przypisane ani do zbioru dominującego, ani do żadnej grupy licencyjnej.

Wskaźnik wyboru kandydata opiera się na \(\mathrm{coverage}(v)\) oraz \(\min\_\mathrm{cpn}(v)\).
\begin{itemize}
  \item $U$ to zbiór wierzchołków jeszcze niepokrytych, który jest bezpośrednią kopią $V$ na początku działania algorytmu. W miarę tworzenia grup wierzchołki są usuwane z $U$.
  \item \(\mathrm{coverage}(v)=|N[v]\cap U|\) to liczba jeszcze niepokrytych węzłów, które może pokryć \(v\).
  \item \(\min\_\mathrm{cpn}(v)\) to minimalny koszt na węzeł dla \(v\), liczony po wszystkich licencjach i dopuszczalnych rozmiarach grupy:
        \[
          \min\_\mathrm{cpn}(v)=\min_{l_t\in L}\;\min_{s\in[m_t,\;\min\{k_t,\ \mathrm{coverage}(v)\}]}\ \frac{c_t}{s}.
        \]
        Interpretacja: wybieramy dla \(v\) najkorzystniejszą licencję i rozmiar grupy, które dają najniższy koszt jednostkowy.
\end{itemize}

\begin{algorithm}[H]
  \caption{Zbiór dominujący z budowaniem grup}\label{alg:ds}
  \begin{algorithmic}[1]
    \Require graf $G=(V,E)$, zbiór typów licencji $L$
    \State $U\gets V$, $D\gets\emptyset$, $R\gets V$
    \While{$U\neq\emptyset$}
    \State dla każdego $v\in V$ policz $\mathrm{coverage}(v)=|(N[v]\cap U|$ oraz $\min\_\mathrm{cpn}(v)$
    \State wybierz $u$ maksymalizujące $\mathrm{coverage}(v)/\min\_\mathrm{cpn}(v)$; jeśli brak rozstrzygnięcia wybierz dowolne $u\in U$
    \State $D\gets D\cup\{u\}$, $U\gets U\setminus N[u]$
    \EndWhile
    \State posortuj $D$ nierosnąco według stopni wierzchołków
    \For{każde $u\in D$}
    \State $S\gets N[u]\cap F$
    \State wybierz najtańszą dopuszczalną licencję dla $u$ i wyznacz grupę $P\subseteq S$ o największym dopuszczalnym rozmiarze; w ostateczności przydziel licencję indywidualną
    \State $F\gets F\setminus P$
    \EndFor
    \State \Return utworzone grupy
  \end{algorithmic}
\end{algorithm}

\paragraph{Złożoność i zastosowanie}
Faza wyboru dominatorów w każdej rundzie przechodzi po wszystkich wierzchołkach, ich sąsiadach i typach licencji, co daje koszt rzędu $O(|V||E|T)$. Faza budowania grup dla każdego dominatora sortuje kandydatów i sprawdza warianty licencji. W gęstych grafach rośnie to do \(O(|V|^3 T \log |V|)\), w rzadkich pozostaje bliżej $O(|V||E|T)$. Heurystyka w krótkim czasie wyznacza pełne pokrycie i dostarcza jakościowe rozwiązanie początkowe dla metod ulepszających.

\subsection{Algorytm losowy}\label{subsec:random}

Algorytm losowy pełni rolę metody odniesienia do oceny jakości rozwiązań generowanych przez inne algorytmy. Weryfikuje poprawność implementacji i stanowi stochastyczny punkt odniesienia. Wierzchołki są przetwarzane w losowej kolejności, a wybór licencji i składu grupy jest losowy w granicach ograniczeń pojemności i sąsiedztwa.

\paragraph{Opis metody}
\begin{enumerate}
  \item Losowana jest kolejność przetwarzania wierzchołków.
  \item Dla bieżącego wierzchołka wyznaczany jest zbiór kandydatów obejmujący jego oraz nieprzydzielonych sąsiadów.
  \item Jeżeli istnieje dopuszczalna licencja, losowany jest typ licencji, rozmiar grupy oraz członkowie grupy z dostępnych kandydatów.
        Rozważano wariant deterministyczny oparty na minimalnym koszcie jednostkowym \(\min_{l,s} c_l/s\), analogiczny do heurystyki zbioru dominującego. W pracy przyjęto jednak w pełni losowy wariant, aby uzyskać neutralny punkt odniesienia dla metaheurystyk.
  \item W przeciwnym razie przydzielana jest najtańsza dostępna licencja indywidualna.
  \item Kroki są powtarzane do pełnego pokrycia grafu.
\end{enumerate}

\paragraph{Uwagi o losowości}
Celem było uzyskanie szerokiego spektrum wyników w losowych warunkach spełniających ograniczenia problemu.
Nie stosowano wariantu wyboru licencji według najlepszego kosztu na węzeł, ponieważ prowadziłoby to do wyniku deterministycznego i zawężenia rozkładu rezultatów.
Rozważano także uruchamianie algorytmu wielokrotnie i wybieranie najlepszego otrzymanego wyniku spośród dużej liczby uruchomień.
Zaobserwowano, że średnia jakość z wielu uruchomień była zbliżona do jakości najlepszego pojedynczego przebiegu.
W eksperymentach algorytm uruchamiano jednokrotnie z ustalonym ziarnem generatora liczb losowych, co umożliwia replikację wyników.

\begin{algorithm}[H]
  \caption{Losowy dobór licencji i składu grupy}\label{alg:randomized}
  \begin{algorithmic}[1]
    \Require graf $G=(V,E)$, zbiór typów licencji $L$
    \State $U\gets V$, $\pi\gets$ losowa permutacja $V$
    \For{node w kolejności $\pi$}
    \If{$node\notin U$} \textbf{continue} \EndIf
    \State $S\gets N[node]\cap U$
    \If{istnieje licencja $l_t$ z $m_t\le |S|$}
    \State losuj $l_t$ oraz rozmiar $s\in\bigl[m_t,\min\{|S|,k_t\}\bigr]$, następnie losuj członków grupy z $S$
    \Comment{wariant kierowany: można zastąpić wyborem $\arg\min_{l_t,s} c_t/s$}
    \Else
    \State przydziel najtańszą licencję indywidualną
    \EndIf
    \State dodaj grupę, usuń jej członków z $U$
    \EndFor
    \While{$U\neq\emptyset$} przydziel najtańszą licencję indywidualną i usuń węzeł z $U$ \EndWhile
  \end{algorithmic}
\end{algorithm}

\paragraph{Złożoność i zastosowanie}
Każdy wierzchołek i jego sąsiedzi są przeglądani co najwyżej raz, a przy każdej próbie losowania licencji przeglądane są wszystkie typy licencji, co daje koszt rzędu \(O\bigl(T(|E|+|V|)\bigr)\).
W gęstych grafach upraszcza się to do \(O(T|V|^2)\).
Algorytm służy jako benchmark stochastyczny oraz kontrola jakości innych metod.
Wariant kierowany \(\min c_t/s\) nie zmienia rzędu złożoności i może być użyty pomocniczo do analizy wrażliwości.


\section{Metaheurystyki}

Metaheurystyki to algorytmy przeszukujące przestrzeń rozwiązań w sposób systematyczny. W przeciwieństwie do heurystyk konstrukcyjnych, metaheurystyki startują od rozwiązania początkowego i iteracyjnie je ulepszają.

\paragraph{Dobór parametrów}
Parametry metaheurystyk zostały dobrane eksperymentalnie na podstawie testów na grafach różnych rozmiarów.

\paragraph{Operacje modyfikacji rozwiązania}
Metaheurystyki ulepszają rozwiązanie, stosując następujące operacje:
\begin{itemize}
  \item zmiana typu licencji używanej przez właściciela grupy
  \item przeniesienie członka z jednej grupy do drugiej
  \item zamiana miejscami dwóch członków z różnych grup
  \item scalanie dwóch grup w jedną lub rozdzielanie na dwie dopuszczalne.
\end{itemize}

\subsection{Algorytm genetyczny}\label{subsec:ga}
Algorytm genetyczny utrzymuje populację pełnych przydziałów licencyjnych i z pokolenia na pokolenie ulepsza je, korzystając z losowych mutacji i krzyżowania par rodziców \cite{holland1975,goldberg1989}. Zaczyna od kilku rozwiązań zachłannych i losowych, a następnie w każdej generacji wybiera najlepsze osobniki (elita), losuje rodziców metodą turniejową i tworzy potomstwo przez krzyżowanie lub mutację. Rozwiązania o niższej jakości są zastępowane lepszymi, a algorytm rejestruje najlepszy dotąd koszt.

\paragraph{Parametry}
\begin{itemize}
  \item \textbf{Wielkość populacji} $P_{GA}=30$ - liczba rozwiązań utrzymywanych w każdej generacji.
  \item \textbf{Liczba pokoleń} $N_{GA}=40$ - maksymalna liczba iteracji ewolucji.
  \item \textbf{Udział elity} $\alpha_{GA}=20\%$ - część najlepszych osobników kopiowana bez zmian do kolejnego pokolenia.
  \item \textbf{Prawdopodobieństwo krzyżowania} $p_{c,GA}=60\%$ - przy tej szansie dziecko powstaje przez połączenie dwóch rodziców; w przeciwnym razie wykonywana jest mutacja.
\end{itemize}

\begin{algorithm}[H]
  \caption{Algorytm genetyczny}
  \label{alg:ga}
  \begin{algorithmic}[1]
    \Require graf $G=(V,E)$, zbiór typów licencji $L$
    \State utwórz populację początkową (zachłanny + losowe rozwiązania)
    \For{każde pokolenie}
    \State oceń wszystkie rozwiązania (funkcja kosztu)
    \State zachowaj elitę (najlepsze rozwiązania)
    \While{populacja niepełna}
    \If{losowanie krzyżowania}
    \State wybierz dwóch rodziców (selekcja turniejowa)
    \State wykonaj krzyżowanie rodziców (połącz komponenty rozwiązań)
    \Else
    \State wybierz rozwiązanie i wykonaj mutację (operacje sąsiedztwa)
    \EndIf
    \State dodaj potomka do nowej populacji
    \EndWhile
    \State zaktualizuj najlepsze znalezione rozwiązanie
    \EndFor
    \State \Return najlepsze rozwiązanie
  \end{algorithmic}
\end{algorithm}

\paragraph{Złożoność i zastosowanie}
Inicjalizacja populacji korzysta z jednego osobnika otrzymanego za pomocą algorytmu zachłannego i $P-1$ losowych rozwiązań, co kosztuje około $O\bigl(P \cdot (|V|T + |E|\log |V|)\bigr)$. Każda generacja sortuje populację ($O(P\log P)$), a następnie tworzy nowe pokolenie. Mutacje wywołują ograniczoną liczbę operatorów sąsiedztwa (zmiana typu licencji, przeniesienie członka, zamiana miejscami, scalanie lub podział grup), a krzyżowanie w razie potrzeby uruchamia heurystykę zachłanną na podgrafie, co w przybliżeniu daje koszt rzędu $O(|V|T + |E|\log |V|)$ na potomka. Łącznie otrzymujemy $O\bigl(G \cdot P \cdot (|V|T + |E|\log |V|)\bigr)$ w najgorszym przypadku. Algorytm działa wolniej od prostych heurystyk, ale potrafi znacząco poprawić ich wyniki i służy jako główna metoda poszukiwania wysokiej jakości rozwiązań, gdy możemy poświęcić na optymalizację więcej czasu.


\subsection{Przeszukiwanie tabu}\label{subsec:tabu}
Algorytm tabu rozpoczyna działanie od rozwiązania uzyskanego heurystyką zachłanną, a następnie iteracyjnie przeszukuje lokalne sąsiedztwo. Sąsiadem nazywa się rozwiązanie otrzymane przez pojedynczą operację mutacji, na przykład zmianę typu licencji właściciela, przeniesienie członka między grupami, zamianę członków lub scalenie i podział grup. Lista tabu przechowuje identyfikatory ostatnich rozwiązań lub ruchów i zakazuje wyboru kandydatów, którzy prowadzą do niedawno odwiedzonych stanów. Kryterium aspiracji pozwala pominąć zakaz, gdy kandydat poprawia najlepszy dotąd koszt. Mechanizm ten ogranicza krótkie cykle i równoważy lokalne doskonalenie z eksploracją nowych przydziałów licencji \cite{glover1989}.

\paragraph{Parametry}
\begin{itemize}
  \item \textbf{Maksymalna liczba iteracji} $I_{tabu}=1000$.
  \item \textbf{Długość listy tabu} $L_{tabu}=20$ elementów.
  \item \textbf{Liczba sąsiadów na iterację} $k_{tabu}=10$.
\end{itemize}

\begin{algorithm}[H]
  \caption{Przeszukiwanie tabu}\label{alg:tabu}
  \begin{algorithmic}[1]
    \Require graf \(G=(V,E)\), zbiór typów licencji \(L\)
    \State \(aktualne \gets\) rozwiązanie początkowe wyznaczone algorytmem zachłannym
    \State \(najlepsze \gets aktualne\)
    \State \(lista\_tabu \gets\) pusta kolejka o stałej długości \(L\); wstaw podpis \(aktualne\)
    \For{każdą iterację}
    \State wygeneruj sąsiedztwo \(aktualne\) przez operacje mutacji
    \State wybierz najlepszego kandydata, którego podpis nie znajduje się na \(lista\_tabu\) lub który poprawia \(najlepsze\) \((\)aspiracja\()\)
    \If{wybrano kandydata}
    \State \(aktualne \gets\) kandydat; zaktualizuj \(lista\_tabu\)
    \If{\(aktualne\) lepsze niż \(najlepsze\)} \State \(najlepsze \gets aktualne\) \EndIf
    \Else
    \State \textbf{przerwij}
    \EndIf
    \EndFor
    \State \Return \(najlepsze\)
  \end{algorithmic}
\end{algorithm}

\paragraph{Złożoność i zastosowanie}
Inicjalizacja początkowego stanu grafu obejmuje jedno uruchomienie heurystyki zachłannej \(O(|V|T + |E|\log |V|)\). W każdej z \(I\) iteracji generowanych jest do \(k\) sąsiadów. Ocena kandydata obejmuje sprawdzenie pojemności, pokrycia i zgodności z sąsiedztwem w grafie, co kosztuje około \(O(|V|T + |E|)\). Łączna złożoność obliczeniowa wynosi w przybliżeniu \(O\!\left(I \cdot k \cdot (|V|T + |E|)\right)\). Przeszukiwanie tabu dobrze sprawdza się jako metoda ulepszająca: poprawia rozwiązania wyjściowe przy umiarkowanym czasie obliczeń i ogranicza powroty do niedawno odwiedzonych stanów dzięki liście tabu.

\subsection{Algorytm mrówkowy}\label{subsec:aco}
Algorytm mrówkowy buduje wiele rozwiązań równolegle. Każda mrówka konstruuje przydział licencji, kierując się siłą śladów feromonowych (informacja o dotychczas dobrych wyborach) oraz heurystyką preferującą wierzchołki o dużym stopniu i licencje o dobrym stosunku pojemności do ceny \cite{dorigo1997}. Po każdej iteracji, czyli po zakończeniu budowy rozwiązań przez wszystkie mrówki w danym kroku, feromony parują, a najlepsze dotąd rozwiązanie wzmacnia ścieżki feromonowe, czyli w przypadku naszej implementacji prawdopodobieństwo wyboru konkretnych właścicieli i typów licencji.
Dzięki temu kolejne mrówki chętniej eksplorują obiecujące fragmenty przestrzeni rozwiązań (tj. wierzchołków i typów licencji).
\paragraph{Parametry}
\begin{itemize}
  \item \textbf{Waga feromonu} $\alpha=1.0$ -- określa, jak mocno mrówki ufają dotychczasowym śladom.
  \item \textbf{Waga heurystyki} $\beta=2.0$ -- wzmacnia lokalnie korzystne decyzje, czyli takie, które przy danym wierzchołku pozwalają dobrać licencję z wysoką pojemnością i niskim kosztem jednostkowym. Koszt jednostkowy to cena licencji $l_t$ podzielona przez liczbę użytkowników w grupie lub cenę licencji indywidualnej.
  \item \textbf{Tempo parowania} $\rho=0.5$ -- część feromonu usuwana po każdej iteracji.
  \item \textbf{Prawdopodobieństwo wyboru zachłannego} $q_0=0.9$ -- z tą szansą mrówka wybiera najlepszą dostępną opcję, w przeciwnym razie losuje wierchołek i licencje proporcjonalnie do wag wyliczonych w trakcie budowy rozwiązania.
  \item \textbf{Liczba mrówek} $A=20$ -- ile rozwiązań konstruujemy równolegle w jednej iteracji.
  \item \textbf{Maksymalna liczba iteracji} $N_{ACO}=100$ -- ile razy aktualizujemy feromony.
  \item \textbf{Losowe ziarno} (opcjonalne) -- pozwala odtworzyć przebieg eksperymentu.
\end{itemize}


\begin{algorithm}[H]
  \caption{Algorytm mrówkowy}
  \label{alg:aco}
  \begin{algorithmic}[1]
    \Require graf $G=(V,E)$, zbiór typów licencji $L$
    \State zainicjalizuj feromony $\tau$ (dla par wierzchołek-licencja)
    \State zainicjalizuj heurystyki $\eta$ (na podstawie stopni wierzchołków i kosztów licencji)
    \State $najlepsze \gets$ rozwiązanie początkowe (zachłanne)
    \For{każdą iterację}
    \For{każdą mrówkę}
    \State $niepokryte \gets V$
    \While{$niepokryte \neq \emptyset$}
    \State wybierz właściciela na podstawie $\tau$ i $\eta$ (reguła wyboru lub ruletka)
    \State wybierz typ licencji na podstawie $\tau$ i $\eta$
    \State utwórz grupę, usuń członków z $niepokryte$
    \EndWhile
    \If{mrówka znalazła lepsze rozwiązanie}
    \State $najlepsze \gets$ rozwiązanie mrówki
    \EndIf
    \EndFor
    \State wyparuj część feromonów: $\tau \gets \tau \cdot (1-evaporation)$
    \State wzmocnij feromony na ścieżce $najlepsze$: $\tau \gets \tau + 1/koszt$
    \EndFor
    \State \Return $najlepsze$
  \end{algorithmic}
\end{algorithm}

\paragraph{Złożoność i zastosowanie}
Inicjalizacje feromonów i heurystyk charakteryzuje złożoność obliczeniowa $O(|V|T)$. Pojedyncza konstrukcja rozwiązania wymaga odwiedzenia przez mrówkę każdego wierzchołka co najwyżej raz. W każdym kroku mrówka wybiera wierzchołek, który stanie się właścicielem nowej grupy licencyjnej; w tym celu ocenia wszystkie niepokryte wierzchołki jako potencjalnych właścicieli oraz wszystkie typy licencji dostępne w zbiorze $L$. Po wskazaniu właściciela trzeba posortować jego sąsiadów w grafie $G$ według wag feromonowo-heurystycznych, aby zdecydować, którzy użytkownicy dołączą do grupy. Te operacje prowadzą do złożoności obliczeniowej rzędu $O(|V|^2 T + |E|\log |V|)$ na jedną mrówkę. Algorytm wykonujący $I$ iteracji z $A$ mrówkami ma więc złożoność $O\!\left(I \cdot A \cdot (|V|^2 T + |E|\log |V|)\right)$. Metoda jest bardziej złożona obliczeniowo niż tabu i algorytm zachłanny, ale pozwala eksplorować wiele alternatywnych konfiguracji i stopniowo wzmacniać najlepsze z nich.


\subsection{Symulowane wyżarzanie }\label{subsec:sa}
Symulowane wyżarzanie rozpoczyna od dowolnego dopuszczalnego przydziału; w implementacji korzystamy z rozwiązania wygenerowanego heurystyką zachłanną. W każdej iteracji losowana jest jedna z operacji modyfikacji opisanych na początku sekcji metaheurystyk. Jeżeli wylosowana operacja prowadzi do stanu naruszającego ograniczenia, losujemy kolejną do chwili znalezienia dopuszczalnego kandydata (maksymalnie kilkanaście prób na iterację). Nowy stan jest akceptowany zawsze, gdy obniża koszt całkowity przydziału licencji, a także niekiedy dla kandydata o wyższym koszcie, z prawdopodobieństwem zależnym od bieżącej temperatury \(T\) i różnicy kosztów \cite{kirkpatrick1983}. Temperatura maleje geometrycznie z czynnikiem chłodzenia, a po przekroczeniu limitu stagnacji \(S\) jest dodatkowo dzielona przez 2. Dzięki temu metoda potrafi opuszczać lokalne minima funkcji kosztu w sąsiedztwie zdefiniowanym przez powyższe operacje i stopniowo stabilizuje się w pobliżu dobrego rozwiązania.

\paragraph{Parametry}
\begin{itemize}
  \item \textbf{Temperatura początkowa} $\tau_0 = 100.0$ - stosunkowo wysoka wartość dobrana eksperymentalnie; przy takich temperaturach różnice kosztów rzędu kilku jednostek są często akceptowane, co pozwala na szeroką eksplorację przestrzeni rozwiązań na początku działania algorytmu.
  \item \textbf{Współczynnik chłodzenia} $\gamma = 0.995$ - temperatura maleje geometrycznie z czynnikiem $\gamma$.
  \item \textbf{Temperatura minimalna} $\tau_{\min} = 0.001$ - po jej osiągnięciu algorytm kończy działanie.
  \item \textbf{Maksymalna liczba iteracji} $N_{SA} = 20\,000$ - górne ograniczenie liczby kroków.
  \item \textbf{Limit stagnacji} $S = 2\,000$ - liczba kolejnych iteracji bez poprawy najlepszej wartości; po jego przekroczeniu temperatura jest dodatkowo dzielona przez 2.
\end{itemize}

\begin{algorithm}[H]
  \caption{Symulowane wyżarzanie}
  \label{alg:sa}
  \begin{algorithmic}[1]
    \Require graf $G=(V,E)$, zbiór typów licencji $L$
    \State $aktualne \gets$ rozwiązanie początkowe (np. zachłanne)
    \State $najlepsze \gets aktualne$
    \State $temperatura \gets T_0$ (początkowa temperatura)
    \For{każdą iterację}
    \If{$temperatura < T_{min}$} \textbf{przerwij} \EndIf
    \State wybierz losową operację sąsiedztwa
    \State $kandydat \gets$ wynik operacji sąsiedztwa
    \State $\Delta \gets koszt(kandydat) - koszt(aktualne)$
    \If{$\Delta \leq 0$ LUB $random() < \exp(-\Delta / temperatura)$}
    \State $aktualne \gets kandydat$
    \If{$koszt(kandydat) < koszt(najlepsze)$}
    \State $najlepsze \gets kandydat$
    \EndIf
    \EndIf
    \State $temperatura \gets temperatura \cdot \gamma$
    \EndFor
    \State \Return $najlepsze$
  \end{algorithmic}
\end{algorithm}

\paragraph{Złożoność i zastosowanie}
Inicjalizacja korzysta z rozwiązania uzyskanego heurystyką zachłanną, co kosztuje $O(|V|T + |E|\log |V|)$. Samo symulowane wyżarzanie może jednak wystartować z dowolnego dopuszczalnego stanu, a heurystyka zapewnia po prostu solidny punkt startowy. W każdej iteracji wykonujemy do kilkunastu prób wygenerowania dopuszczalnego sąsiada z katalogu operacji, a zaakceptowany kandydat przechodzi pełną walidację pokrycia i ograniczeń, co ma złożoność około $O(|V|T + |E|)$. W rezultacie całkowity koszt jednego przebiegu wynosi $O\bigl(I \cdot (|V|T + |E|)\bigr)$ z dodatkowym czynnikiem wynikającym z epizodycznego obniżania temperatury po przekroczeniu limitu stagnacji $S$. Symulowane wyżarzanie ma umiarkowane wymagania obliczeniowe, a możliwość wychodzenia z lokalnych minimów funkcji kosztu czyni je skuteczną metodą poprawy jakości rozwiązań przy rozsądnym czasie działania.

\section{Podsumowanie}

W rozdziale przedstawiono kompletny zestaw algorytmów zastosowanych do rozwiązania problemu optymalizacji kosztów licencji grupowych. Metody podzielono na trzy kategorie: algorytmy dokładne gwarantujące optimum, szybkie heurystyki konstrukcyjne oraz metaheurystyki łączące jakość z efektywnością czasową.

Algorytmy dokładne -- naiwne przeszukiwanie oraz programowanie całkowitoliczbowe -- zapewniają najwyższą jakość rozwiązań, ale ich zastosowanie ogranicza się do mniejszych instancji ze względu na złożoność wykładniczą. Algorytm ILP stanowi szczególnie wartościowy punkt odniesienia, umożliwiając walidację jakości metod przybliżonych na grafach do około 200 węzłów.

Heurystyki konstrukcyjne charakteryzują się bardzo krótkim czasem działania (rzędu milisekund) i mogą służyć jako metody bazowe lub punkty startowe dla bardziej zaawansowanych algorytmów. Algorytm zachłanny dostarcza rozsądnie dobrej jakości rozwiązań przy minimalnym koszcie obliczeniowym, natomiast heurystyka oparta na zbiorze dominującym wykorzystuje teorię grafów do identyfikacji kandydatów na właścicieli licencji.

Metaheurystyki stanowią kompromis między jakością a czasem wykonania. Algorytm genetyczny skutecznie eksploruje przestrzeń rozwiązań poprzez mechanizmy krzyżowania i mutacji, przeszukiwanie tabu wykorzystuje pamięć krótkoterminową do unikania cykli, algorytm mrówkowy buduje rozwiązania probabilistycznie na podstawie feromonów, a symulowane wyżarzanie umożliwia wychodzenie z lokalnych minimów dzięki kontrolowanej losowości.

Różnorodność przedstawionych metod pozwala na dobór odpowiedniego algorytmu w zależności od rozmiaru instancji, dostępnego budżetu czasowego oraz wymagań jakościowych. W eksperymentach empirycznych metody te zostaną porównane pod kątem efektywności na rzeczywistych i syntetycznych sieciach społecznych.
