Imię i nazwisko studenta: Marcin Połajdowicz Nr albumu: 184265 Poziom kształcenia: studia drugiego stopnia Forma studiów: stacjonarne Kierunek studiów: Informatyka Specjalność: Algorytmy i technologie internetowe Imię i nazwisko studenta: Maciej Sztramski Nr albumu: 184779 Poziom kształcenia: studia drugiego stopnia Forma studiów: stacjonarne Kierunek studiów: Informatyka Specjalność: Aplikacje rozproszone i systemy internetowe PRACA DYPLOMOWA MAGISTERSKA Tytuł pracy w języku polskim: Modelowanie optymalnych sposobów zakupu licencji oprogramowania w sieciach społecznościowych za pomocą dominowania w grafach Tytuł pracy w języku angielskim: Modeling optimal ways to purchase software licenses in social networks via graph domination Opiekun pracy: dr inż. Joanna Raczek Streszczenie PLACHOLDER: Celem niniejszej pracy magisterskiej było opracowanie grafowego modelu optymalizacji zakupu licencji oprogramowania (np. Duolingo Super, Spotify Premium) w sieciach społecznościowych. Problem ten rozpatrzono jako rozszerzenie problemu dominowania rzymskiego w grafach, uwzględniając dodatkowe ograniczenia dotyczące maksymalnego rozmiaru grup licencyjnych (od 2 do 6 osób) oraz różnic w kosztach licencji indywidualnych i grupowych. W pracy przeprowadzono analizę złożoności obliczeniowej problemu, wykazując jego NP- -trudność. Zastosowano różnorodne podejścia algorytmiczne, od metod dokładnych (programowanie matematyczne MIP) po heurystyki i metaheurystyki (algorytm zachłanny, algorytmy genetyczne, tabu search, symulowane wyżarzanie, reinforcement learning). Badania eksperymentalne przeprowadzono na rzeczywistych danych sieci społecznościowych (Ego-Facebook, Google+) oraz na danych syntetycznych (Barabási–Albert, Erdős–Rényi, Watts–Strogatz). Otrzymane wyniki eksperymentalne wykazały, że metaheurystyki, takie jak algorytmy genetyczne oraz reinforcement learning, zapewniają najlepsze kompromisy między jakością rozwiązania a czasem działania. Analiza dynamicznej wersji problemu potwierdziła skuteczność algorytmów adaptacyjnych przy zmianach struktury sieci w czasie. Dodatkowo przeanalizowano wpływ różnych polityk cenowych oraz dodatkowych planów subskrypcyjnych na decyzje zakupowe użytkowników. Wskazano potencjalne zastosowania modelu w różnych branżach oraz zaproponowano kierunki dalszych badań. Słowa kluczowe: teoria grafów, optymalizacja kombinatoryczna, dominowanie rzymskie, sieci społecznościowe, metaheurystyki, zakup licencji, algorytmy genetyczne, reinforcement learning. Abstract PLACHOLDER: The aim of this master’s thesis was to develop a graph-based model for optimizing software license purchases (e.g., Duolingo Super, Spotify Premium) within social networks. The problem was formulated as an extension of classical Roman domination problems in graph theory, incorporating practical constraints such as group-size limitations and specific licensing costs. This thesis analyzes the computational complexity of the problem, demonstrating its NP- -hard nature. Various algorithmic approaches were implemented and compared, including exact methods (Mixed Integer Programming - MIP), heuristics, and advanced metaheuristics (genetic algorithms, Tabu Search, simulated annealing, reinforcement learning). The algorithms were evaluated experimentally on both real-world datasets (from SNAP and NetworkRepository) and synthetic graph models (Barabási–Albert, Erdős–Rényi, Watts–Strogatz). Experimental results indicate that metaheuristic approaches, particularly genetic algorithms and reinforcement learning, effectively balance solution quality and computational efficiency. The thesis also explores dynamic scenarios in evolving social networks, demonstrating the 2 effectiveness of adaptive algorithms in maintaining cost-efficiency. Furthermore, the impact of varying pricing strategies and additional subscription types (e.g., Duo, Student plans) on consumer choices was investigated. The applicability of the proposed model in different industries was discussed, along with recommendations for future research directions. Keywords: graph theory, combinatorial optimization, Roman domination, social networks, metaheuristics, license purchase optimization, NP-hard problems. 3 SPIS TREŚCI Wykaz ważniejszych oznaczeń i skrótów 6 1 Wprowadzenie 7 1.1 Wstęp i motywacja . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 1.2 Cele i zakres pracy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 1.3 Struktura pracy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 2 Model grafowy problemu zakupu licencji 10 2.1 Reprezentacja grafowa . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 2.2 Definicja problemu . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 2.3 Koszty i ograniczenia . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 2.3.1 Ograniczenia techniczne i społeczne współdzielenia licencji . . . . . . . . . 12 2.3.2 Struktura kosztów i modele cenowe . . . . . . . . . . . . . . . . . . . . . . 12 2.3.3 Zakup jednoczesny i sekwencyjny . . . . . . . . . . . . . . . . . . . . . . . 13 3 Związek z dominowaniem w grafach 14 3.1 Dominowanie - podstawowe definicje . . . . . . . . . . . . . . . . . . . . . . . . . 14 3.2 Dominowanie rzymskie a licencje grupowe . . . . . . . . . . . . . . . . . . . . . . 15 3.3 Złożoność obliczeniowa problemu . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 4 Dane testowe 19 4.1 Grafy syntetyczne . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 4.1.1 Model Erdős–Rényi - klasyczne grafy przypadkowe . . . . . . . . . . . . . 19 4.1.2 Model Barabási–Albert - sieci bezskalowe . . . . . . . . . . . . . . . . . . . 20 4.1.3 Model Watts–Strogatz (graf małego świata) . . . . . . . . . . . . . . . . . . 21 4.2 Grafy rzeczywiste . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 5 Metody algorytmiczne optymalizacji kosztów licencji 27 5.1 Dokładne algorytmy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 5.1.1 Programowanie całkowitoliczbowe . . . . . . . . . . . . . . . . . . . . . . . 27 5.1.2 Algorytm naiwny . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 5.1.3 Branch and Bound . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 5.1.4 Programowanie dynamiczne na drzewach . . . . . . . . . . . . . . . . . . . 32 5.2 Algorytmy przybliżone . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 5.2.1 Algorytm zachłanny . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 5.2.2 Algorytm dla zbioru dominującego . . . . . . . . . . . . . . . . . . . . . . . 35 5.2.3 Algorytm losowy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 4 5.3 Metaheurystyki . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 5.3.1 Algorytm genetyczny . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 5.3.2 Tabu Search . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 5.3.3 Algorytm mrówkowy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39 5.3.4 Symulowane wyżarzanie (Simulated Annealing) . . . . . . . . . . . . . . . 41 6 Eksperymenty i analiza wyników 43 6.1 Kryteria oceny . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 6.2 Środowisko testowe . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 6.3 Eksperymenty . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 6.3.1 Eksperymenty na grafach rzeczywistych . . . . . . . . . . . . . . . . . . . . 43 6.3.2 Eksperymenty na grafach syntetycznych . . . . . . . . . . . . . . . . . . . 43 6.4 Wpływ parametrów na efektywność algorytmów . . . . . . . . . . . . . . . . . . . . 44 5 WYKAZ WAŻNIEJSZYCH OZNACZEŃ I SKRÓTÓW Oznaczenia G = (V, E) – Graf reprezentujący sieć społecznościową. V – Zbiór wierzchołków grafu (użytkowników sieci społecznościowej). E – Zbiór krawędzi reprezentujących relacje między użytkownikami. u, v ∈ V – Pojedyncze wierzchołki (użytkownicy). Skróty SaaS – Software as a Service, model biznesowy udostępniający oprogramowanie jako usługę. 6 1. WPROWADZENIE 1.1 Wstęp i motywacja W ostatnich latach obserwuje się dynamiczny rozwój modeli subskrypcyjnych w sektorze oprogramowania i usług cyfrowych. Zgodnie z indeksem gospodarki subskrypcyjnej rynek ten zwiększyła swoją wartość o ponad 400% od roku 2012 do roku 2021 [1] oraz osiągając w 2024 przybliżoną wartość prawie 600 miliardów dolarów [2]. Konsumenci coraz częściej opłacają regularne abonamenty zamiast jednorazowych zakupów, co zapewnia firmom stałe przychody, a użytkownikom wygodny dostęp do usług. Wiele popularnych platform, w tym aplikacje edukacyjne, serwisy streamingowe czy oprogramowanie SaaS, opiera się na modelu subskrypcji. Przykładowo, serwisy Netflix czy Spotify oferują plany rodzinne, w których kilka osób może współdzielić jedno konto, którego koszt jest sumarycznie niższy od zakupu kilku indywidualnych licencji. Podobnie platforma Duolingo udostępnia plan Rodzina Super Duolingo (ang. Duolingo Super Family) [3], pozwalający grupie znajomych lub rodzinie na współdzielenie konta premium. Zachęca to użytkowników do grupowego zakupu licencji, redukując koszt przypadający na jedną osobę. Kontekst społeczny odgrywa tu bardzo istotną rolę. Rozsądne i optymalne korzystanie z subskrypcji grupowych wymaga, aby główny posiadacz konta znał osoby zainteresowane wspólnym korzystaniem z usługi - czy to ze względu na chęć dzielenia kosztów, czy wspólną pasję. Rozwój mediów społecznościowych i komunikatorów ułatwia zawieranie takich porozumień w gronie znajomych lub osób o podobnych zainteresowaniach. W praktyce często dochodzi do sytuacji, w których użytkownicy umawiają się na wspólny zakup abonamentu. Sieć powiązań społecznych decyduje o tym, kto z kim może efektywnie współdzielić licencję. Od strony technologicznej platformy cyfrowe wspierają takie rozwiązania poprzez funkcje zakładania profili dla wielu użytkowników w ramach jednego konta czy umożliwienie jednoczesnego dostępu z kilku urządzeń. Analiza przedstawionych mechanizmów prowadzi do sformułowania problemu optymalizacyjnego polegającego na takim zaplanowaniu zakupu licencji w grupie powiązanych użytkowników, które pozwala na minimalizację łącznych kosztów. Innymi słowy, mając daną sieć znajomości oraz dostępne opcje licencyjne, jak dobrać podzbiór użytkowników kupujących licencje (oraz rodzaj tych licencji), by wszyscy użytkownicy mieli dostęp do usługi przy możliwie najniższym sumarycznym koszcie. Intuicyjnie, jest to problem pokrycia grafu pewnym zbiorem ”liderów” (osób wykupujących licencje) w taki sposób, by każdy w grafie był albo sam licencjonowany, albo połączony z kimś, kto licencję posiada. W dalszej części pracy przedstawione zostanie, że problem ten można sprowadzić do klasycznego problemu teorii grafów zwanego dominowaniem w grafach, a konkretnie do jego wariantu zwanego dominowaniem rzymskim. 7 1.2 Cele i zakres pracy Celem niniejszej pracy jest formalizacja i analiza problemu optymalnego zakupu licencji w sieciach społecznościowych, zaproponowanie metod jego rozwiązania oraz sprawdzenie przyjętych rozwiązań. W pierwszej kolejności opracowany zostanie model grafowy opisujący powiązania między użytkownikami oraz różne strategie zakupowe wraz z odpowiadającymi im kosztami. Taki model pozwoli zdefiniować problem minimalizacji kosztów - jako zadanie optymalizacyjne na grafie. Następnym celem pracy jest wykazanie, że problem ten jest ściśle powiązany z problemem dominowania w grafach, znanym z teorii grafów. W szczególności pokazane zostanie, że dla pewnej klasy modeli licencjonowania zadanie optymalnego doboru subskrypcji jest równoważne znalezieniu tak zwanego zbioru dominującego minimalnej wielkości lub rozwiązaniu pokrewnego problemu dominacji rzymskiej. Wyznaczenie ich wzajemnej korelacji umożliwi odwołanie się do znanych wyników z teorii dominowania, takich jak wyniki dotyczące złożoności obliczeniowej czy algorytmów aproksymacyjnych, co pozwoli lepiej zrozumieć trudności badanego problemu oraz zaprojektować efektywne metody jego rozwiązywania. Zakres pracy obejmuje analizę teoretyczną oraz rozważania nad metodami algorytmicznymi rozwiązania problemu. Rozpatrzone zostaną różne modele cenowe licencji, które odpowiadać będą rzeczywistym różnicom cen między licencjami indywidualnymi a grupowymi. Pod uwagę zostaną wzięte również wybrane przypadki hipotetyczne, w tym między innymi takie, w których koszt licencji grupowej stanowi dwukrotność lub trzykrotność ceny licencji indywidualnej. Uwzględnione zostaną również warianty problemu, w których decyzje dotyczące zakupu licencji podejmowane są globalnie, czyli jednocześnie dla całej społeczności użytkowników oraz scenariusze dynamiczne. W scenariuszu dynamicznym zakupy mogą być realizowane w kolejnych krokach czasowych, a struktura sieci społecznościowej może ulegać zmianom poprzez rozszerzanie lub zmniejszanie się puli użytkowników oraz zanikanie lub powstawanie nowych relacji - połączeń między użytkownikami. Ponadto, ze względu na wysoką złożoność obliczeniową problemu, w pracy omówiony zostanie przegląd potencjalnych algorytmów zarówno dokładnych jak i heurystycznych, które mogą znaleźć rozwiązania dobrej jakości w akceptowalnym czasie. Celem praktycznym jest wskazanie, jakie podejścia mogą być skuteczne przy optymalizacji kosztów subskrypcji w dużych sieciach społecznościowych oraz zidentyfikowanie czynników, które najbardziej wpływają na końcowe wyniki optymalizacji. 1.3 Struktura pracy Praca została podzielona na dziewięć rozdziałów, które skupią się na wprowadzeniu do omawianego zagadnienia, przedstawią wyniki pracy nad poszukiwanymi dla danego problemu rozwiązaniami oraz przedstawia wnioski co do zrealizowanej pracy. W dalszej części przedstawiony jest szczegółowy opis zawartości poszczególnych rozdziałów. • Rodział 1 - Przedstawia tło problemu, motywację podjęcia tematu, cele oraz zakres pracy, a także strukturę całej pracy. 8 • Rodział 2 - Zawiera formalny opis modelu grafowego dla sieci społecznościowej oraz definicję analizowanego problemu optymalizacji kosztów. Omówiono tam przyjęte założenia oraz różne warianty problemu wynikające z modeli cenowych i harmonogramu zakupów. • Rodział 3 - Dotyczy pojęcia dominowania w grafach i jego związku z naszym problemem. Wprowadzone zostają definicje zbioru dominującego oraz dominowania rzymskiego, a następnie pokazana jest interpretacja naszego problemu w tych kategoriach. Rozdział ten porusza też kwestie złożoności obliczeniowej - wykazuje NP-trudność problemu oraz omawia jej konsekwencje dla dalszych analiz. • Rodział 4 - Skupia się na algorytmicznych aspektach problemu. Przedstawiona zostaje formalizacja zadania w postaci programu całkowitoliczbowego oraz omówione są znane w literaturze metody dokładne znajdowania minimalnych zbiorów dominujących. Rozdział ten zawiera również przegląd wybranych algorytmów przybliżonych i heurystyk, które potencjalnie można zastosować do dużych grafów społecznościowych. • Rodział 5 - Prezentuje proponowane rozwiązania heurystyczne opracowane w ramach pracy. Opisane zostaną autorskie algorytmy heurystyczne dostosowane do specyfiki problemu licencji. Zaprezentowane zostaną również ewentualne algorytmy wyszukiwania lokalnego i strategie poprawy znalezionych rozwiązań. • Rodział 6 - Rozszerza analizę na wersje dynamiczne problemu. Rozważane jest scenariusz, w którym zakupy licencji dokonywane są w sekwencji, a sieć użytkowników może się zmieniać. Omówiony zostaje wpływ takiej dynamiki na strategię optymalną oraz ewentualne podejścia algorytmiczne. • Rodział 7 - Zawiera opis przeprowadzonych eksperymentów i symulacji. Przedstawione zostaną wyniki testów algorytmów na przykładowych grafach symulujących sieci społeczne. Analizie poddano różne konfiguracje, a uzyskane wyniki zestawiono pod kątem jakości rozwiązań i czasów obliczeń. • Rodział 8 - Interpretowane są obserwacje poczynione na podstawie eksperymentów - na przykład jak struktura sieci wpływa na oszczędności kosztów, jaka jest efektywność poszczególnych algorytmów, w jakich warunkach współdzielenie licencji przynosi największe korzyści. Poruszone zostają także aspekty praktyczne wdrożenia strategii grupowego zakupu subskrypcji oraz potencjalne ograniczenia. • Rodział 9 - Zawiera wnioski wynikające z przeprowadzonych badań, podkreśla osiągnięte cele oraz proponuje kierunki dalszych badań. Wskazane są możliwe usprawnienia modeli oraz rozwinięcia algorytmów. Rozdział ten kończy pracę, syntetycznie odpowiadając na pytanie sformułowane na początku i sugerując, jak uzyskane rezultaty mogą zostać wykorzystane w praktyce. 9 2. MODEL GRAFOWY PROBLEMU ZAKUPU LICENCJI 2.1 Reprezentacja grafowa Aby formalnie opisać zjawisko współdzielenia licencji, sieć relacji społecznych modelujemy jako graf nieskierowany G = (V, E). Każdy wierzchołek v ∈ V reprezentuje pojedynczego użytkownika, natomiast krawędź {u, v} ∈ E oznacza, że użytkownicy u i v znajdują się w relacji umożliwiającej współdzielenie licencji - na przykład jako znajomi lub członkowie rodziny. Graf jest nieskierowany, ponieważ zakładamy symetryczność tej relacji: jeśli u zna v, to również v zna u. Przyjmujemy również, że graf G nie zawiera pętli, tj. {v, v} ∈/ E dla każdego v ∈ V , ani krawędzi wielokrotnych - każda para użytkowników może być powiązana co najwyżej jedną krawędzią. Przykład takiej struktury zilustrowano na Rysunku 2.1. Rysunek 2.1: Przykładowy graf relacji społecznych między użytkownikami. Opisana reprezentacja, w której wierzchołki odpowiadają jednostkom, a krawędzie bezpośrednim relacjom umożliwiającym interakcję, jest powszechnie stosowana w analizie sieci społecznościowych [4, 5]. Takie ujęcie pozwala formalnie modelować i badać zjawiska zachodzące w społecznościach użytkowników usług cyfrowych. W przyjętym modelu zakłada się, że współdzielenie licencji może odbywać się wyłącznie między osobami połączonymi bezpośrednią krawędzią w grafie. Oznacza to, że użytkownicy muszą znać się bezpośrednio i mieć wzajemne zaufanie, co jest istotne na przykład w przypadku przekazywania danych logowania lub zapraszania do planu rodzinnego. Relacje pośrednie, w których użytkownicy są powiązani poprzez wspólnych znajomych (np. A ∼ B oraz B ∼ C, lecz brak bezpośredniego powiązania A ∼ C), nie są uwzględniane w analizie. Oznacza to, że dla danego grafu G = (V, E), w którym V to zbiór użytkowników, a E ⊆ {{u, v} : u, v ∈ V, u 6= v} to zbiór relacji znajomości, analizie podlegają wyłącznie relacje bezpośrednie, czyli pary {u, v} ∈ E. Na przykład w grafie przedstawionym na Rysunku 2.1, użytkownicy A i D są wprawdzie połączeni za pośrednictwem ścieżki A → C → D, jednak ponieważ brakuje bezpośredniego połączenia {A, D} ∈ E, to taka relacja nie jest uznawana za podstawę do współdzielenia licencji w tym modelu. Mimo że w praktyce relacje pośrednie - takie jak ścieżki długości większej niż jeden - mogą sprzyjać tworzeniu grup subskrypcyjnych, nie są one brane pod uwagę w rozważanym modelu. 10 Graf społecznościowy nie musi być pełny - dopuszcza się dowolną strukturę odpowiadającą rzeczywistym relacjom społecznym. W analizie istotną rolę odgrywa stopień wierzchołków, ponieważ decyduje on o liczbie osób, którym dany użytkownik może udostępnić swoją licencję. Dla wierzchołka v ∈ V , jego stopień oznaczamy przez deg(v), co odpowiada liczbie sąsiadów użytkownika v w grafie G = (V, E). Należy jednak zauważyć, że nawet w przypadku wysokiego stopnia deg(v), użytkownik niekoniecznie może współdzielić licencję ze wszystkimi swoimi sąsiadami. Ograniczenia techniczne, takie jak limity liczby współużytkowników narzucane przez dostawcę usługi, sprawiają, że liczba osób objętych jedną licencją grupową pozostaje ograniczona. W analizowanym modelu można zatem przyjąć dodatkowy parametr k, oznaczający maksymalną liczbę osób, z którymi użytkownik może dzielić licencję, przy czym k ≤ deg(v). 2.2 Definicja problemu Optymalizacja kosztu dostępu do usługi wymaga przypisania wierzchołkom grafu G = (V, E) odpowiednich ról. Każdy użytkownik v ∈ V może uzyskać dostęp do usługi na trzy sposoby: 1. poprzez wykupienie licencji indywidualnej o koszcie c1 = 1, 2. poprzez wykupienie licencji grupowej o koszcie cg = p, 3. jako odbiorca, korzystający z licencji grupowej należącej do znajomego. Licencja indywidualna zapewnia dostęp wyłącznie jej właścicielowi, natomiast licencja grupowa umożliwia współdzielenie dostępu z maksymalnie L − 1 sąsiadami w grafie. Aby precyzyjnie sformułować model, wprowadzone zostały trzy zbiory, reprezentujące użytkowników wykupujących konkretne licencje: 1. I - zawierający użytkowników z licencjami indywidualnymi, 2. G - obejmujący użytkowników z licencjami grupowymi, 3. R = V \ (I ∪ G) - czyli odbiorców nieposiadających własnej licencji. Aby rozwiązanie było wykonalne, każdy odbiorca musi mieć sąsiada z licencją grupową, użytkownicy z licencją grupową nie mogą współdzielić dostępu z więcej niż L − 1 osobami, a zarówno użytkownicy z licencją grupową, jak i indywidualną muszą zapewniać sobie dostęp samodzielnie. W celu uproszczenia analizy oraz z myślą o późniejszym sprowadzeniu problemu do wariantu dominowania rzymskiego, przypisujemy każdemu wierzchołkowi jedną z trzech etykiet: 0 oznacza odbiorcę (użytkownika bez własnej licencji), 1 odpowiada użytkownikowi z licencją indywidualną, natomiast 2 reprezentuje użytkownika posiadającego licencję grupową. Taki sposób etykietowania pozwala w prosty sposób wyrazić warunki wykonalności: każdy wierzchołek o etykiecie 0 musi być połączony z przynajmniej jednym sąsiadem o etykiecie 2, natomiast każdy wierzchołek o etykiecie 2 może współdzielić swoją licencję z co najwyżej L − 1 odbiorcami. Przedstawiony model odpowiada wariantowi problemu pokrycia wierzchołków grafu, w którym tylko wierzchołki o etykiecie 2 mogą pokrywać sąsiadów, a wierzchołki o etykiecie 1 pokrywają jedynie same siebie. 11 Łączny koszt rozwiązania wyraża się wzorem: C = |I| + p · |G|, gdzie p oznacza względny koszt licencji grupowej względem indywidualnej. Celem optymalizacji jest znalezienie takiego podziału zbioru V = I ∪ G ∪ R, który spełnia wszystkie warunki wykonalności i minimalizuje całkowity koszt C. Odpowiadający problem decyzyjny polega na sprawdzeniu, czy istnieje taki wybór zbiorów I i G, że spełnione są wszystkie warunki oraz zachodzi nierówność: |I| + p · |G| ≤ K, dla danego ograniczenia kosztowego K. 2.3 Koszty i ograniczenia 2.3.1 Ograniczenia techniczne i społeczne współdzielenia licencji Kluczowym parametrem modelu jest maksymalna liczba osób L, które mogą współdzielić jedną licencję grupową, wliczając w to użytkownika nabywającego licencję. Parametr L jest zwykle narzucany przez dostawcę usługi. Przykładowo, plan rodzinny Spotify Premium pozwala na korzystanie maksymalnie sześciu osobom (właściciel + pięć członków rodziny), co odpowiada wartości L = 6. Z kolei najwyższy plan Netflixa umożliwia jednoczesne oglądanie na czterech urządzeniach, które interpretowane są jako czterech użytkowników, co w naszym modelu również przekłada się na L = 4. W przypadku Duolingo Super Family plan obejmuje do sześciu profili (L = 6). W analizie przyjmujemy L jako zmienny parametr, przy czym należy podkreślić, że nawet jeśli użytkownik posiada wielu znajomych (czyli ma wysoki stopień w grafie), ograniczenie L sprawia, iż może objąć współdzieleniem tylko ograniczoną liczbę osób. Część jego znajomych będzie musiała skorzystać z innych źródeł dostępu. Parametr L modeluje również czynnik zaufania społecznego, gdyż w praktyce użytkownicy rzadko dzielą się kontem z wieloma niezależnymi osobami. Grupy współdzielenia najczęściej tworzą się w niewielkich gronach, takich jak rodzina czy bliscy przyjaciele. Nasz model odwzorowuje to zjawisko, ograniczając wielkość ”gwiazdy” dominacji jednego użytkownika właśnie poprzez limit L. 2.3.2 Struktura kosztów i modele cenowe Przyjmujemy, że koszt licencji indywidualnej wynosi 1 jednostkę, natomiast koszt licencji grupowej oznaczamy przez p. W rzeczywistych ofertach wartość p różni się w zależności od usługi, lecz zazwyczaj jest mniejsza niż suma kosztów indywidualnych licencji dla wszystkich użytkowników planu, co stanowi zachętę do współdzielenia. W szczególności interesujące są przypadki, gdy p < L, ponieważ wtedy koszt jednostkowy w planie grupowym, równy p/L, jest niższy niż 1. 12 Jeżeli natomiast p = L, oznaczałoby to brak korzyści ze współdzielenia - koszt na osobę byłby identyczny jak w przypadku zakupu licencji indywidualnej. W praktyce jednak zazwyczaj zachodzi p < L, a często nawet p  L, co czyni współdzielenie ekonomicznie korzystnym. Do zilustrowania różnych scenariuszy rozważane będą miedzy innymi poniższe modele cenowe: 1. Model A: p = 2, L = 5 - licencja grupowa dwukrotnie droższa od indywidualnej, obejmująca pięć osoby, 2. Model B: p = 3, L = 5 - licencja grupowa trzykrotnie droższa od indywidualnej, również obejmująca pięć osób. Zarówno model A jak i model B reprezentują rzeczywisty rozmiar ilości osób mogących korzystać z jednej zakupionej licencji grupowej. Istotną różnicą jest tutaj cena obu tych przypadków. Interesujący może być wpływ ceny na ilość występowania zakupionych licencji indywidualnych oraz grupowych w porównaniu modeli o różnych wartości obu tych licencji. 2.3.3 Zakup jednoczesny i sekwencyjny W podstawowej wersji problemu zakłada się, że decyzje zakupowe wszystkich użytkowników są podejmowane jednocześnie, co umożliwia globalną optymalizację. W praktyce jednak proces współdzielenia często przebiega dynamicznie. Najpierw pewne grupy użytkowników kupują licencje indywidualnie, a dopiero później tworzą grupy współdzielenia. Taki dynamiczny scenariusz można modelować jako proces wieloetapowy, w którym w kolejnych krokach następuje przydział użytkowników do nowych licencji. Warto zauważyć, że rozwiązanie optymalne przy jednoczesnym zakupie może być trudne do osiągnięcia w procesie sekwencyjnym. Decyzje podejmowane wcześniej mogą ograniczać dostępne opcje w kolejnych etapach. W pracy omówione zostaną wyzwania związane z rozwiązaniami sekwencyjnymi, takie jak stabilność struktur współdzielenia czy mechanizmy motywujące do współpracy. Główny nacisk kładziony jest jednak na analizę wariantu jednoczesnego, który umożliwia zastosowanie klasycznych narzędzi teorii grafów i optymalizacji dyskretnej, oraz stanowi punkt odniesienia dla bardziej złożonych scenariuszy dynamicznych. 13 3. ZWIĄZEK Z DOMINOWANIEM W GRAFACH 3.1 Dominowanie - podstawowe definicje Problematyka dominowania w grafach jest dobrze zbadana i szeroko opisana w literaturze [6]. Niech G = (V, E) będzie grafem nieskierowanym. Zbiorem dominującym nazywamy podzbiór wierzchołków D ⊆ V taki, że każdy wierzchołek spoza D ma co najmniej jednego sąsiada w D, tj. ∀v ∈ V \ D ∃ u ∈ D : {u, v} ∈ E. Minimalną liczność zbioru dominującego oznaczamy symbolem γ(G) i nazywamy liczbą dominowania: γ(G) = min |D| : D ⊆ V, D jest zbiorem dominującym w G 	 . Z punktu widzenia rozważanego problemu zakupu licencji, podstawowe założenie jest następujące: jeśli potraktujemy osoby kupujące licencje jako zbiór D, a krawędzie grafu jako relacje umożliwiające udostępnianie licencji, wówczas warunek dominowania opisuje sytuację, w której każdy użytkownik spoza D ma znajomego z D, a zatem uzyskuje dostęp do usługi. Gdyby wszystkie licencje były identyczne i pozwalały obsłużyć dowolną liczbę sąsiadów, minimalizacja kosztu sprowadzałaby się do wyznaczenia γ(G). W praktyce jednak występują różne typy licencji (indywidualne i grupowe) oraz limity współużytkowników, co czyni problem znacznie bardziej złożonym. Należy zauważyć, że minimalny zbiór dominujący nie musi być jednoznaczny - często graf ma wiele różnych zbiorów dominujących o rozmiarze równym γ(G) (jak na Rys. 3.1, gdzie dwa różne zbiory czerwonych wierzchołków są minimalne). Problem znajdowania γ(G) jest jednak dobrze określony i - co istotne - jest on problemem NP-trudnym. Decyzyjna wersja problemu zbioru dominującego („czy w grafie G istnieje zbiór dominujący wielkości co najwyżej k?”) jest klasycznym problemem NP-zupełnym [7, 8, 9]. Oznacza to, że najprawdopodobniej (przy założeniu P 6= NP) nie istnieje wielomianowy algorytm znajdujący minimalny zbiór dominujący dla dowolnego grafu. W praktyce stosuje się zatem algorytmy przybliżone lub ogranicza przypadek do specjalnych klas grafów, dla których problem może stać się łatwiejszy. Istnieją efektywne algorytmy zachłanne, dające przybliżenie rozwiązania z gwarantowanym współczynnikiem - np. prosty algorytm zachłanny wybierający kolejno dominujące wierzchołki daje przybliżenie rzędu O(ln n). 14 Rysunek 3.1: Przykładowe zbiory dominujące (wyróżnione na czerwono). (a) Zbiór dominujący o mocy 3 (nieminalny). (b)-(c) Dwa różne minimalne zbiory dominujące o mocy 2, zatem γ(G) = 2. Każdy wierzchołek nieczerwony ma sąsiada czerwonego. Wiadomo jednak, że nie da się w ogólności przekroczyć bariery logarytmicznej - problem zbioru dominującego jest APX-trudny, a dokładniej log-APX-zupełny [8]. Co więcej, nawet na bardzo ograniczonych grafach, np. grafach o maksymalnym stopniu 3 (grafy kubiczne), problem pozostaje NP-trudny i APX-zupełny [10]. Berman i Fujito (1999) wykazali m.in. NP-trudność pewnych wariantów dominacji w grafach o ograniczonym stopniu [11], co potwierdza, że zasadnicza trudność problemu dominowania jest obecna już w stosunkowo prostych strukturach. 3.2 Dominowanie rzymskie a licencje grupowe Dominowanie rzymskie (ang. Roman domination) to wariant problemu dominacji, w którym wierzchołki mogą przyjmować trzy stany: 0 (niezdominowany), 1 (dominacja tylko samego siebie) lub 2 (dominacja rozszerzona na sąsiadów). Formalnie, funkcja dominacji rzymskiej na grafie G = (V, E) to funkcja f : V → 0, 1, 2 spełniająca warunek, że dla każdego wierzchołka v z f(v) = 0 istnieje co najmniej jeden jego sąsiad u ∈ V taki, że f(u) = 2 [12]. Wierzchołki z etykietą 2 pełnią rolę „silnych dominatorów”, którzy dominują zarówno siebie, jak i sąsiadów - można je porównać do wierzchołków umieszczających dwie jednostki obrony: jedną chroniącą ich samych i jedną zdolną zabezpieczyć sąsiada. Wierzchołki z etykietą 1 dominują wyłącznie siebie (odpowiednik pojedynczej jednostki obrony niewystarczającej, by ochronić kogoś innego), zaś etykieta 0 oznacza brak dominacji (wymagający ochrony z zewnątrz). Terminologia nawiązuje do legendy o obronie imperium rzymskiego - stąd nazwa; pojęcie to zostało wprowadzone w teorii grafów przez Cockayne’a i współpracowników w 2004 roku [13]. W kontekście naszego problemu interpretacja jest bezpośrednia: etykieta f(v) = 2 odpowiada użytkownikowi v, który wykupił licencję grupową (przez co zabezpiecza „dostęp” sobie oraz przynajmniej jednemu sąsiadowi). Etykieta f(v) = 1 odpowiada użytkownikowi z licencją indywidualną (zapewniającą dostęp tylko jemu samemu). Natomiast f(v) = 0 oznacza użytkownika bez własnej licencji, który musi polegać na dostępie od kogoś innego. Warunek dominacji rzymskiej, że każdy 0 ma sąsiada 2, gwarantuje dokładnie to, co w naszym modelu jest wymagane - każda osoba bez licencji ma znajomego z licencją grupową, który może się z nią podzielić dostępem. W ten sposób, każda funkcja f : V → 0, 1, 2 spełniająca warunki dominacji rzymskiej wyznacza pewną realizację strategii licencyjnej w naszej sieci. 15 Waga funkcji dominacji rzymskiej definiowana jest jako w(f) = P v∈V f(v), czyli suma przypisanych wartości. Liczba dominacji rzymskiej γR(G) to najmniejsza możliwa waga funkcji dominacji rzymskiej dla grafu G. Jeśli przyjmiemy, że koszt licencji indywidualnej wynosi 1, a grupowej to 2, to minimalizacja kosztu w naszym problemie pokrywa się dokładnie z zagadnieniem znalezienia funkcji dominacji rzymskiej o minimalnej wadze. Cel minimalizacji sumarycznego kosztu C = |I|+2|G| jest zatem identyczny z minimalizacją w(f), gdy utożsamimy |I| z liczbą wierzchołków o etykiecie 1, a |G| - o etykiecie 2. Innymi słowy, dla przypadku p = 2 problem optymalnego zakupu licencji jest równoważny problemowi dominacji rzymskiej na grafie znajomości. W przypadku innych modeli cenowych, dominacja rzymska stanowi nadal użyteczną metaforę, choć nie oddaje w sposób wystarczający struktury kosztów. Gdy p 6= 2, możemy rozważyć ogólniejsze przypisania wag: np. jeśli p = 3, to licencja grupowa ma „wagę” 3 jednostek kosztu, co nie mieści się w klasycznym schemacie 0, 1, 2 (gdzie 2 jest maksymalną wartością). Istnieją jednak rozszerzenia pojęcia dominacji rzymskiej - np. k-dominacja rzymska, gdzie używa się wartości 0, 1, . . . , k [14], albo koncepcja dominacji rzymskiej z wagami [15]. W przypadku p = 3 można by dopuścić etykietę 3 oznaczającą specjalny rodzaj wierzchołka ze zbioru dominującego zdolnego ochraniać dwóch sąsiadów, co odpowiadałoby planowi droższemu, ale o większej pojemności. W literaturze pojawiły się uogólnienia pokrewne temu pomysłowi, np. tzw. dominacja podwójnie rzymska i inne warianty. Na potrzeby tej pracy nie musimy jednak wchodzić w tak szczegółowe odmiany. Wystarczy stwierdzić, że dominowanie rzymskie bardzo dobrze modeluje sytuację zakupu licencji w przypadku najprostszego i dość reprezentatywnego modelu. W praktyce, jeśli p jest większe, strategia optymalna często i tak polega na wykorzystaniu licencji grupowych do pełnego obsadzenia nimi maksymalnej liczby osób, co czyni opis dominacją rzymską użytecznym do wyznaczenia „kto powinien kupić licencję grupową” (etykiety 2) a kto może pozostać bez zakupu (0) lub ewentualnie kupić licencję indywidualną (1). Przeanalizujmy prosty przykład obrazujący wykorzystanie dominacji rzymskiej. Weźmy graf w kształcie gwiazdy: jeden centralny wierzchołek A połączony z kilkoma liśćmi B, C, D, E. Intuicyjnie, najlepszą strategią jest, by centralny użytkownik A wykupił licencję grupową, z której skorzystają wszyscy jego sąsiedzi. W naszym modelu odpowiada to przypisaniu f(A) = 2, zaś dla każdego liścia X ∈ B, C, D, E przypisaniu f(X) = 0. Warunek dominacji rzymskiej jest spełniony, bo każdy 0 (np. B) ma sąsiada A z f(A) = 2. Waga takiej funkcji to w(f) = 2 + 0 + 0 + 0 + 0 = 2. Rzeczywiście, koszt dla grupy A, B, C, D, E wynosi 2 (jedna licencja grupowa). Gdybyśmy zamiast tego wybrali strategię indywidualną dla każdego (wszyscy f = 1), waga wyniosłaby 5, a koszt 5. Gdyby centralny kupił licencję indywidualną, a liście pozostałyby bez dostępu, warunek nie byłby spełniony bo liście nie miałyby sąsiada z 2. Przykład ten przedstawiony jest na Rysunku 3.2 i pokazuje, jak dominacja rzymska wskazuje optymalny wybór „lidera” (centrum gwiazdy) z mocniejszym statusem (2). Oczywiście, w większych grafach może być wielu kandydatów na licencje grupowe - problem ich doboru to właśnie zagadnienie optymalnej dominacji rzymskiej. W interpretacji dominacji rzymskiej warto wspomnieć, że oryginalna inspiracja historyczna 16 Rysunek 3.2: (a) Przypisanie optymalne (koszt 2). (b) Wszyscy z f = 1 (koszt 5). (c) A = 1, liście f = 0 (niespełniony warunek). zakładała, iż wierzchołek z dwoma „oddziałami” (etykieta 2) może w razie potrzeby przenieść jeden oddział do sąsiada pozbawionego obrony (). W naszej analogii oznacza to, że osoba z licencją grupową może udostępnić dostęp przynajmniej jednemu znajomemu. Jeśli dany „silny” wierzchołek ma wielu sąsiadów oznaczonych 0, to formalnie warunki dominacji rzymskiej są spełnione. Jednak w interpretacji praktycznej jeden abonament grupowy ma ograniczoną liczbę slotów, więc jeden użytkownik nie może nieograniczenie wielu osobom zapewnić dostępu. Stąd nasz problem jest nieco bardziej ograniczony niż klasyczne dominowanie rzymskie - jeden wierzchołek 2 może „pokryć” co najwyżej L wierzchołków 0 (sąsiadów). Gdy L jest małe, może zajść potrzeba, by niektóre duże gwiazdy w grafie miały więcej niż jeden „silny” wierzchołek. Mimo tego ograniczenia, wiele intuicji z teorii dominacji rzymskiej wciąż obowiązuje przy konstruowaniu rozwiązań - wierzchołki 2 powinny być rozmieszczone tak, by objąć wszystkich 0 w swoim sąsiedztwie, a wierzchołki 1 będą pojawiać się tylko tam, gdzie opłaca się komuś kupić indywidualnie zamiast korzystać od kogoś. 3.3 Złożoność obliczeniowa problemu Skoro udało się sprowadzić problem zakupu licencji do problemu dominowania w grafach, można skorzystać z wiedzy o złożoności tego zagadnienia. Niestety, problem ten okazuje się NP-trudny w ogólności. Już klasyczny problem zbioru dominującego jest NP-zupełny (decyzyjnie) [16], a dominowanie rzymskie również należy do klasy problemów NP-trudnych. Istnieje redukowanie problemu dominacji rzymskiej do dominującego lub odwrotnie dla wielu klas grafów, co wskazuje na zbliżony poziom trudności. Intuicyjnie, dopuszczenie stanów 0,1,2 czyni problem co najmniej tak trudnym jak zwykłe dominowanie - można to sobie wyobrazić, zauważając że jeśli ograniczyć rozwiązania dominacji rzymskiej do takich, gdzie f(v) przyjmuje tylko wartości 0 lub 1, to znajdujemy się w ustawieniu odpowiadającym zwykłemu dominowaniu. Zatem dominacja rzymska ogólna zawiera jako podprzypadek dominację klasyczną, co implikuje NP-trudność. Dokładniejsze dowody złożoności znajdują się w literaturze - np. pokazano NP-zupełność problemu dominacji rzymskiej poprzez redukcję z pokrycia wierzchołków lub zbioru dominującego [17]. W kontekście naszego problemu oznacza to, że optymalne wyznaczenie, którzy użytkownicy powinni kupić jakie licencje, jest obliczeniowo trudne dla dużych sieci. Mówiąc wprost, nie istnieje znany algorytm, który w czasie wielomianowym znajdzie rozwiązanie minimalnego kosztu dla do17 wolnej struktury znajomości - trzeba by sprawdzić kombinacje wyborów, co w najgorszym razie rośnie wykładniczo z liczbą wierzchołków. Konsekwencją NP-trudności jest także brak prostego schematu aproksymacyjnego dla problemu minimalizacji kosztów licencji. Ponieważ problem dominowania (minimalnego zbioru dominującego) jest APX-zupełny (dla konkretnych rodzajów grafów) [8], nie ma wielomianowego schematu aproksymacji (PTAS) gwarantującego dobre przybliżenie. Dla naszego problemu, który jest uogólnieniem dominowania, można oczekiwać podobnych ograniczeń - prawdopodobnie nie da się znaleźć w czasie wielomianowym rozwiązań bliższych optimum niż o czynnik O(ln n) w najgorszym przypadku. Proste heurystyki zachłanne mogą jednak dawać przyzwoite wyniki. Na przykład, heurystyka wybierająca iteracyjnie wierzchołek, który pokrywa najwięcej jeszcze niepokrytych sąsiadów (i dająca mu licencję grupową), jest jedną z implementacji algorytmu zachłannego dla zbioru dominującego i osiąga współczynnik ≈ (2+ln ∆), gdzie ∆ to maksymalny stopień grafu [18]. W najgorszym razie jest to O(ln n), ale dla wielu grafów rzeczywiste wyniki są lepsze niż ta pesymistyczna granica. Ważnym faktem jest też to, że problem pozostaje trudny nawet dla grafów o niewielkich stopniach - np. wykazano, że dla grafów o stopniu mniejszym bądź równym cztery minimum dominujące jest APX-zupełne [10, 8]. To implikuje, że ograniczenie maksymalnej liczby znajomych (np. każdy ma co najwyżej czterech znajomych) nie czyni problemu trywialnym. W kontekście subskrypcji oznacza to, że nawet w sieci gdzie każdy zna tylko kilka osób, optymalny dobór kto z kim powinien się połączyć we wspólnej licencji nadal może wymagać złożonych obliczeń. Biorąc powyższe pod uwagę, w dalszej części pracy główny nacisk zostanie położony na podejścia algorytmiczne, które biorą pod uwagę tę złożoność. Ponieważ nie istnieje wydajny algorytm dokładny dla ogólnego przypadku, rozważymy dwutorowo: (a) zastosowanie metod dokładnych dla umiarkowanych rozmiarów oraz (b) zaprojektowanie i analiza algorytmów heurystycznych zdolnych dawać dobre rozwiązania dla większych sieci. W literaturze pojawiły się już pierwsze próby wykorzystania technik optymalizacyjnych do problemu dominacji. Przykładowo, Parra Inza i in. (2022) zaproponowali sformułowanie problemu dominującego jako ILP oraz heurystyki naprawcze dla jego rozwiązywania [19]. Takie podejście można zaadaptować do omawianego problemu, wprowadzając zmienne decyzyjne wskazujące wybór typu licencji dla każdego użytkownika i ograniczenia. Z drugiej strony, heurystyki takie jak algorytm zachłanny, algorytmy lokalnej optymalizacji czy metaheurystyki - np. algorytmy genetyczne, symulowane wyżarzanie - mogą być użyte, by szybko przeszukać przestrzeń możliwych konfiguracji licencji. 18 4. DANE TESTOWE W celu przeprowadzenia szczegółowej analizy efektywności algorytmów optymalizujących zakup licencji w sieciach społecznościowych niezbędne jest wykorzystanie różnorodnych danych testowych. Posłużą do tego syntetycznie generowane grafy losowe oraz rzeczywiste fragmenty sieci społecznościowej. Pierwsza grupa stanowi kontrolowany zbiór danych sztucznych, pozwalający na symulowanie różnych scenariuszy topologicznych i analizę wpływu struktury sieci na działanie algorytmów. Druga grupa to rzeczywiste ego-sieci z platformy Facebook, umożliwiające weryfikację metod na prawdziwych danych społecznościowych. 4.1 Grafy syntetyczne Do generowania danych syntetycznych wykorzystano zaimplementowaną w ramach pracy klasę GraphGeneratorFactory, która umożliwia tworzenie losowych grafów o zadanych parametrach przy użyciu różnych popularnych modeli generowania sieci. W szczególności obsługiwane są generatory takie jak model Erdős–Rényi, Barabási–Albert oraz Watts–Strogatz. 4.1.1 Model Erdős–Rényi - klasyczne grafy przypadkowe Pierwszym rozważanym modelem jest klasyczny losowy graf Erdős–Rényi (ER) zaproponowany przez Erdős’a i Rényi’ego w 1959 roku [20]. W modelu tym rozpatruje się zbiór n wierzchołków, a każda z n 2  potencjalnych krawędzi pojawia się niezależnie z prawdopodobieństwem p. Parametrami modelu są więc n (liczba wierzchołków) oraz p (prawdopodobieństwo powstania pojedynczej krawędzi). W implementacji GraphGeneratorFactory zaadaptowano właśnie ten wariant G(n, p). Model ER stanowi istotny punkt odniesienia jako najprostszy model sieci pozbawiony struktury społecznościowej. Motywacją uwzględnienia go w testach jest możliwość porównania działania algorytmów na zupełnie przypadkowych sieciach z ich działaniem na bardziej uporządkowanych grafach (skalowanych, małego świata oraz rzeczywistych). Choć prawdziwe sieci społecznościowe odbiegają od założeń pełnej losowości (np. mają zwykle wyższy poziom klasteryzacji węzłów i nierównomierny rozkład stopni), to jednak model G(n, p) posiada podstawę porównawczą. Z punktu widzenia właściwości, grafy ER cechują się stosunkowo niskim średnim współczynnikiem klasteryzacji (oczekiwana wartość współczynnika klasteryzacji jest równa p dla dużego n) oraz (dla dostatecznie dużego p) powstawaniem jednej gigantycznej składowej spójnej. Istnieje znana granica perkolacji: gdy p przekroczy około ln n n , graf G(n, p) jest z dużym prawdopodobieństwem spójny – poniżej tego progu sieć rozpada się na wiele komponentów [20]. Gęstość grafu (rozumiana jako odsetek istniejących krawędzi w stosunku do wszystkich możliwych) wynosi w tym modelu w przybliżeniu p (np. dla p = 0.1 graf będzie miał ok. 10% maksymalnej liczby 1 krawędzi). Rozkład stopni w modelu ER ma charakter dwumianowy, a w granicy dużego n zbiega do rozkładu Poissona. Oznacza to, że w grafach tych nie występują węzły o niezwykle wysokich stopniach (tzw. huby), które są charakterystyczne dla wielu rzeczywistych sieci społecznych. W konsekwencji model ER nie oddaje wielu kluczowych właściwości takich sieci – stanowi jednak użyteczny model kontrolny, pozbawiony zjawisk typu „mały świat” czy „skalowość”, dzięki czemu można wyraźnie uwypuklić wpływ tych cech w innych modelach. 4.1.2 Model Barabási–Albert - sieci bezskalowe Drugim wykorzystanym generatorem jest model Barabási–Albert (BA), wprowadzony przez Barabási’ego i Alberta w 1999 roku [21]. Model BA pozwala generować grafy o strukturze bezskalowej, których rozkład stopni wierzchołków przyjmuje postać potęgową. Tego typu sieci charakteryzują się istnieniem niewielkiej liczby wierzchołków o bardzo wysokim stopniu (tzw. hubów) oraz wielu wierzchołków o małym stopniu – jest to cecha obserwowana w wielu rzeczywistych sieciach, w tym społecznościowych (np. niektórzy użytkownicy mogą mieć tysiące znajomych/obserwujących, podczas gdy większość ma ich kilkudziesięciu lub mniej). Parametrem wejściowym modelu Barabási–Albert w implementacji GraphGeneratorFactory jest przede wszystkim n – docelowa liczba węzłów w grafie – oraz m – liczba krawędzi, jakie dodaje każdy nowy węzeł. Procedura generowania rozpoczyna się od małego grafu startowego (np. klika złożona z m wierzchołków, aby zapewnić początkową spójność). Następnie dodaje się kolejno nowe wierzchołki; każdy nowy węzeł łączy się z m już istniejącymi wierzchołkami, przy czym prawdopodobieństwo połączenia z danym istniejącym węzłem jest proporcjonalne do jego bieżącego stopnia (tzw. reguła preferencyjnego łączenia, ang. preferential attachment). W efekcie „bogaci stają się bogatsi” – wierzchołki, które zyskały wiele połączeń na wcześniejszych etapach, mają większą szansę zdobyć kolejne połączenia, co prowadzi do wykładniczego (potęgowego) rozkładu stopni. Motywacją użycia modelu BA było odzwierciedlenie w danych testowych właściwości często spotykanej w sieciach społecznościowych i sieciach informacji – silnego zróżnicopwania w stopniach węzłów. Dzięki grafom BA można przetestować algorytmy pod kątem radzenia sobie z obecnością hubów oraz z rozkładem stopni o ciężkim ogonie (ang. heavy-tailed distribution). Pojęcie ciężkiego ogona oznacza, że prawdopodobieństwo wystąpienia wierzchołków o bardzo dużym stopniu maleje stosunkowo wolno – w efekcie w sieci, obok wielu węzłów o niskim stopniu, pojawia się również pewna liczba hubów o ekstremalnie wysokim stopniu. Zjawisko to odróżnia sieci bezskalowe od np. grafów ER, w których prawdopodobieństwo pojawienia się węzłów o bardzo dużej liczbie sąsiadów jest znikome. Grafy generowane modelem BA mają z reguły jedną spójną komponentę (przy założeniu, że graf startowy jest spójny i m ≥ 1, każdy nowy wierzchołek dołącza do istniejącej struktury, więc sieć pozostaje spójna). Średni stopień w takim grafie wynosi około 2m. Stąd gęstość grafu BA maleje wraz ze wzrostem n – dla dużych grafów jest ona rzędu 2m n , co oznacza, że grafy te są rzadkie. W przeciwieństwie do modelu ER, współczynnik skupienia grafów BA nie jest deter20 minowany przez pojedynczy parametr w oczywisty sposób – klasyczny model BA generuje sieci o stosunkowo niskim średnim clusteringu (niższym niż obserwowany w rzeczywistych sieciach społecznych), ponieważ nowe połączenia tworzone są głównie z hubami, co sprzyja tworzeniu gwiazd zamiast trójkątów. Istnieją modyfikacje modelu BA dodające mechanizmy triadycznego dosłączania, które zwiększają clustering – jednak w czystej postaci model BA zazwyczaj skutkuje średnim współczynnikiem skupienia malejącym wraz z rozmiarem grafu. Niemniej jednak, nawet przy relatywnie niskim clusteringu, grafy BA zachowują własność małych średnich odległości. Powyższe cechy sprawiają, że grafy BA stanowią przydatny model testowy – oddają one istnienie hubów i krótkie odległości jak w wielu sieciach społecznych, choć nie odwzorowują silnego grupowania lokalnego. 4.1.3 Model Watts–Strogatz (graf małego świata) Trzecim fundamentalnym modelem zaimplementowanym w GraphGeneratorFactory jest model Watts–Strogatz (WS), opisany przez Wattsa i Strogatza w 1998 roku [22]. Umożliwia on generowanie grafów małego świata (small-world networks), które łączą w sobie dwie istotne cechy: wysoki współczynnik skupienia (podobny do obserwowanego w sieciach regularnych, np. sieci sąsiedztw) oraz niską średnią odległość (podobnie jak w grafach losowych). Model ten odzwierciedla fakt, że w sieciach społecznych często występują silnie zżyte grupy znajomych (wysokie clustering w skali lokalnej), a jednocześnie dowolne dwie osoby są połączone relatywnie krótką ścieżką znajomości. Generacja grafu WS wymaga trzech parametrów: n – liczby wierzchołków, k – stopnia każdego wierzchołka w początkowej regularnej strukturze oraz p – prawdopodobieństwa przepięcia (ang. rewiring) krawędzi. Procedura rozpoczyna się od utworzenia grafu regularnego: każdy wierzchołek jest połączony z k najbliższymi sąsiadami w pierścieniu (tj. tworzymy pierścień z n węzłów, a następnie każdy węzeł łączymy z k 2 następnymi i k 2 poprzednimi na pierścieniu, zakładając dla uproszczenia, że k jest parzyste). Tak powstała sieć ma wysokie lokalne skupienie – węzły sąsiadujące na pierścieniu tworzą krótkie kliki. Jednocześnie początkowa średnia odległość jest stosunkowo duża (graf ma strukturę pierścienia, więc dystans między węzłami oddalonymi na pierścieniu jest znaczny). Następnie, w modelu WS wprowadza się losowe przepięcia: dla każdej krawędzi łączącej węzeł z jednym z k 2 najbliższych sąsiadów „z prawej strony” pierścienia – dokonuje się, z prawdopodobieństwem p, przepięcia jednego końca tej krawędzi do losowo wybranego innego wierzchołka. Przepięcie polega na usunięciu oryginalnej krawędzi i dodaniu nowej krawędzi łączącej dany węzeł z innym losowym węzłem (według oryginalnej pracy Wattsa–Strogatza unika się powielania istniejących krawędzi i pętli, wybierając tylko takie nowe połączenie, które nie istniało wcześniej). W wyniku tych losowych przepięć przy zachowaniu większości lokalnych połączeń pierścienia otrzymujemy graf, który dla małych p wciąż ma wysoki współczynnika klasteryzacji, ale jednocześnie kilka losowych „skoków” znacząco skraca średnie odległości w sieci. Dla umiarkowanych wartości p (np. p ≈ 0.01 czy 0.1) sieć uzyskuje bardzo małą średnią odległość – zbliżoną do grafów 21 losowych – podczas gdy clustering pozostaje o rząd wielkości wyższy niż w grafie Erdős–Rényi o porównywalnej gęstości. To właśnie fenomen „małego świata”: jednoczesne występowanie silnego grupowania lokalnego i krótkich ścieżek globalnych [22]. W kontekście modelowania sieci społecznych, generator dla modelu WS dodano w celu odzwierciedlenia właściwości, których brakuje modelowi BA – mianowicie wysokiego lokalnego współczynnika klasteryzacji. Sieci społeczne cechują się tym, że znajomi często znają się nawzajem, tworząc kliki znajomych. Model WS pozwala symulować taką sytuację i sprawdzić, jak algorytmy radzą sobie np. z wykrywaniem społeczności czy zjawisk rozprzestrzeniania się informacji w warunkach silnego grupowania. Parametr k decyduje o początkowej gęstości połączeń lokalnych – większe k to więcej krawędzi lokalnych (każdy węzeł ma początkowo k sąsiadów), a zatem wyjściowo wyższy współczynnik klasteryzacji i gęstość. Parametr p natomiast kontroluje losowość grafu: dla p = 0 otrzymujemy graf regularny, zaś dla p = 1 graf staje się w dużej mierze losowy. W praktycznych zastosowaniach interesujący jest zakres p między 0 a 1, gdzie pojawia się mały świat. Grafy WS generowane do testów miały parametry dobrane w taki sposób, aby możliwie dobrze odwzorowywać cechy typowe dla niedużych sieci społecznych. Uzyskiwane w ten sposób sieci charakteryzowały się relatywnie niską gęstością, ale jednocześnie wysokim współczynnikiem klasteryzacji, znacznie przewyższającym wartości obserwowane w losowych grafach ER o podobnej gęstości. Dzięki temu w grafach WS obecne są realistyczne zgrupowania lokalne, odpowiadające typowym kręgom znajomych w sieciach społecznych. Co istotne, sieci te z reguły pozostają spójne – niemal wszystkie wierzchołki należą do jednej dużej komponenty, a ewentualne izolowane węzły pojawiają się jedynie sporadycznie przy skrajnych ustawieniach parametrów. Taka struktura sprawia, że model WS stanowi dobre środowisko testowe. barabasi_n100_m2_example.png Rysunek 4.1: Przykład grafu Barabási-Albert (n = 100, m = 2) wygenerowanego syntetycznie. Widoczne jest istnienie kilku węzłów o wysokim stopniu (hubów) oraz licznych węzłów peryferyjnych o małej liczbie połączeń. 22 4.2 Grafy rzeczywiste Drugim zestawem danych testowych są rzeczywiste grafy pochodzące z sieci społecznościowej Facebook, a dokładniej zbiór Facebook Ego Network udostępniony w ramach Stanford Network Analysis Project (SNAP). Dane te zostały zebrane w 2012 roku przez J. McAuley i J. Leskovca z Uniwersytetu Stanforda w ramach badań nad automatycznym wykrywaniem kręgów społecznych. Zbiór zawiera dziesięć tzw. ego-sieci - sieci ego-centrycznych poszczególnych użytkowników Facebooka, pozyskane za zgodą uczestników poprzez specjalną aplikację facebookową. Ego-sieć to sieć społeczna z perspektywy pojedynczego użytkownika (zwanego ego) - węzłami są ego oraz wszystkie jego bezpośrednie znajome osoby, zaś krawędzie reprezentują relacje znajomości pomiędzy tymi znajomymi. W udostępnionych danych każda z dziesięciu sieci odpowiada innemu użytkownikowi (ego) i zawiera wyłącznie jego znajomych oraz powiązania między nimi. Węzeł ego nie jest jawnie ujęty jako wierzchołek w grafie (można go traktować jako ukrytą centralną jednostkę łączącą wszystkich znajomych). Innymi słowy, graf zapisany w pliku X.edges dotyczy tylko znajomych użytkownika X i relacji między nimi - sam X nie pojawia się w pliku jako węzeł. Do wczytania i wykorzystania tych danych rzeczywistych w testach zaimplementowano klasę RealWorldDataLoader, która przetwarza pliki udostępnione przez SNAP. Każda ego-sieć zapisana jest w osobnych plikach tekstowych, których nazwa odpowiada identyfikatorowi ego (np. 0.edges, 0.circles, 0.feat, 0.egofeat dla ego o ID=0). Struktura danych jest następująca: Plik .edges - lista krawędzi w grafie znajomych danego ego. Każdy wiersz zawiera dwie liczby - identyfikatory dwóch różnych znajomych ego, między którymi istnieje relacja koleżeńska. Krawędzie te są nieskierowane. Ważną cechą jest to, że plik .edges nie zawiera połączeń od ego do jego znajomych - wierzchołek ego w ogóle nie występuje w tym pliku. Oznacza to, że rzeczywista sieć ego (gdyby uwzględnić w niej węzeł ego) miałaby dodatkowo krawędź łączącą ego z każdym z pojawiających się znajomych, jednak tych połączeń tutaj nie zapisano (są one domyślne - zakładamy, że ego jest połączone ze wszystkimi swoimi znajomymi). Pominięcie węzła ego jest zabiegiem celowym, pozwalającym skupić się na relacjach wewnątrz kręgów znajomych. Konsekwencją tego jest często podział grafu znajomych na kilka komponentów - jeśli ego ma różne grupy znajomych wzajemnie się nieznających, to w pliku .edges każda taka grupa stanowi osobną składową spójną (ego, jako jedyny łącznik, został usunięty z grafu). Przykładowo, w ego- -sieci 0.edges znajomi tworzą 5 odrębnych komponentów spójnych. Oznacza to, że użytkownik o ID 0 miał około pięć niezależnych grup znajomych niepowiązanych ze sobą - dopiero poprzez jego osobę (ego) stawały się one pośrednio połączone. Z perspektywy testów algorytmów, analiza takiego grafu pozwala sprawdzić, czy badane metody potrafią wykryć istnienie tych podgrup w sieci. Plik .circles - zestaw kręgów znajomych zdefiniowanych przez użytkownika (ego). Każdy wiersz pliku reprezentuje jeden krąg towarzyski. Wiersz rozpoczyna się od nazwy kręgu - jednak w udostępnionych danych nazwy te zostały zanonimizowane lub pominięte, więc w praktyce 23 każdy wiersz zaczyna się od identyfikatora kręgu albo pustej nazwy, po czym następuje lista ID użytkowników należących do tego kręgu. Kręgi mogą częściowo się pokrywać i nie muszą stanowić rozłącznych społeczności w sensie grafu - są to raczej dodatkowe metadane od ego, opisujące jak kategoryzuje on swoich znajomych. Informacje te mogą być cenne pomocniczo, np. w oryginalnej pracy McAuley’ego i Leskovca posłużyły do oceny algorytmów automatycznie wykrywających społeczności. W niniejszej pracy dane z plików .circles nie były bezpośrednim przedmiotem analizy, ale zostały wczytane i zachowane w strukturze danych na potrzeby ewentualnej interpretacji wyników (np. sprawdzenia, czy wykryte przez algorytmy grupy pokrywają się z kręgami zdefiniowanymi przez użytkownika). Plik .feat - macierz cech atrybutów przypisanych do znajomych ego. Każdy wiersz odpowiada jednemu znajomemu i zawiera wektor wartości cech tej osoby. Cechy te mogą obejmować informacje z profilu Facebooka (np. miejsce pracy, szkoła, zainteresowania itp.). W udostępnionym zbiorze wartości atrybutów zostały zanonimizowane - nie znamy dokładnego znaczenia poszczególnych cech, jedynie ich binarne wartości (1 - użytkownik posiada daną cechę, 0 - nie posiada). Istnieje także plik .featnames zawierający oryginalne nazwy cech, ale w przypadku Facebooka nazwy te również zostały zanonimizowane (np. zamiast “szkoła: Uniwersytet Stanford” pojawia się “anonimowa cecha 57”). W niniejszej pracy dane atrybutów nie były wykorzystywane przez algorytmy (skupiono się na strukturze grafów), jednak klasa RealWorldDataLoader została przygotowana tak, aby wczytać także te informacje na potrzeby ewentualnej rozbudowy eksperymentów o analizę wielowarstwową (np. użycie cech węzłów do ulepszenia detekcji społeczności lub zbadania zjawiska homofilii). Plik .egofeat - wektor cech centralnego użytkownika (ego), w tym samym formacie co pojedynczy wiersz pliku .feat, odnoszący się jednak do ego. Pozwala to porównać cechy ego z cechami jego znajomych. W kontekście naszych badań plik ten również nie był bezpośrednio wykorzystywany, poza podstawową walidacją danych (sprawdzenie spójności liczby cech itp.). Klasa RealWorldDataLoader wczytuje powyższe pliki dla zadanych identyfikatorów sieci, tworząc na ich podstawie wewnętrzną reprezentację grafu (lista sąsiedztwa przy użyciu struktury Graph z biblioteki NetworkX) oraz opcjonalnie zbierając informacje o atrybutach i kręgach znajomych. W implementacji tej klasy wykorzystano funkcje biblioteki NetworkX do dodawania wierzchołków i krawędzi na podstawie list znajomych (plik .edges), jak również do obliczania podstawowych parametrów sieci (np. współczynnik klasteryzacji, gęstość). Na potrzeby testów skupiliśmy się głównie na strukturze grafu znajomych (czyli krawędziach z plików .edges), gdyż to na grafach opierają się badane algorytmy. Spośród dziesięciu dostępnych ego-sieci Facebooka wybrano do eksperymentów te, które spełniały założone kryterium rozmiaru: od 20 do 200 wierzchołków (nie licząc węzła ego). Zbyt małe sieci (poniżej 20 węzłów) byłyby mało reprezentatywne i mogły nie zawierać wyraźnych struktur, z kolei zbyt duże (powyżej 200 węzłów) były trudniejsze w ręcznej analizie oraz mogły znacząco wydłużyć czas działania niektórych algorytmów. Identyfikatory wybranych sieci to między innymi: 3980, 414, 686 oraz 698 - każda z nich zawiera od kilkudziesięciu do ok. 150-200 węzłów. Sieci te pochodzą z oryginalnego zbioru SNAP i odpowiadają anonimo24 wym użytkownikom Facebooka oznaczonym tymi ID. Poniżej przedstawiono podstawowe statystyki i właściwości tych grafów rzeczywistych: Rozmiar sieci (liczba węzłów i krawędzi) Wybrane ego-sieci mają różną wielkość, mieszcząc się jednak w przedziale 20-200 wierzchołków, oraz od kilkudziesięciu do kilku tysięcy krawędzi. Przykładowo, sieć o ID 3980 zawiera kilkudziesięciu użytkowników (dokładna liczba wierzchołków to ok. 30-40) i relatywnie niewielką liczbę połączeń między nimi (rzędu kilkudziesięciu krawędzi, w zależności od tego ilu spośród znajomych danego ego wzajemnie się znało). Z kolei większa sieć o ID 414 ma już blisko 200 węzłów i kilkaset krawędzi. Ogólnie im większa liczba znajomych danego ego, tym potencjalnie więcej połączeń między nimi - aczkolwiek zależy to od charakteru społecznego samego ego (niektórzy użytkownicy pełnią rolę “łączników” różnych grup, inni mają kilka odrębnych grup znajomych). Warto zauważyć, że po połączeniu wszystkich 10 ego-sieci zbiór obejmuje łącznie 4039 unikalnych wierzchołków oraz 88234 krawędzi. Ilustruje to, jak duże mogą być sumarycznie sieci osobistych kontaktów - średnio pojedynczy uczestnik miał kilkuset znajomych, a między nimi istniało bardzo wiele połączeń. My jednak analizujemy każdą sieć oddzielnie, gdyż są one niezależne (choć w oryginalnym zbiorze zaobserwowano, że niektórzy uczestnicy mieli wspólnych znajomych, przez co ego-sieci nie są całkowicie rozłączne - zdarza się, że jeden wierzchołek należy do dwóch ego-sieci, jeśli dwaj uczestnicy badania byli znajomymi). Jak wspomniano, z powodu braku węzła ego w grafie znajomych większość ego-sieci dzieli się na więcej niż jedną składową spójną. W praktyce zazwyczaj istnieje jedna dominująca komponenta, zawierająca największą grupę wzajemnie powiązanych znajomych, oraz kilka mniejszych komponentów (np. dwu- lub kilkuosobowych grup) odpowiadających odizolowanym kręgom towarzyskim. Dla przykładu, sieć 107.edges (niewykorzystana u nas ze względu na rozmiar) okazała się całkowicie spójna - wszyscy znajomi użytkownika 107 tworzyli jeden klaster połączony również ze sobą. Natomiast sieć 0.edges (333 węzły) miała 5 komponentów - co już sygnalizowano wcześniej. Wśród naszych analizowanych sieci: sieć 686.edges jest spójna (1 komponent), sieć 414.edges dzieli się na 2 komponenty, sieć 698.edges na 3, a sieć 3980.edges na 4 komponenty. Zwykle największy komponent obejmuje zdecydowaną większość wierzchołków (np. w sieci 414.edges ponad 80% znajomych należy do jednego klastra, a reszta tworzy małą odrębną grupkę). Taka struktura wskazuje na obecność jednego głównego kręgu znajomych, uzupełnionego kilkoma mniejszymi grupami znajomości niepowiązanych z resztą. Ego-sieci Facebooka cechują się na ogół wysokim clusteringiem, co zgodne jest z intuicją - znajomi konkretnej osoby często znają się nawzajem. W literaturze podaje się, że globalny współczynnik klasteryzacji dla całego grafu Facebooka jest stosunkowo niski, ale wynika to z faktu, że taka metryka obejmuje również połączenia między ludźmi, którzy nie mają żadnych wspólnych znajomych. Natomiast w obrębie pojedynczej ego-sieci (gdzie wszyscy rozważani ludzie są znajomymi jednego ego) współczynnik skupienia jest znacznie wyższy. Dla połączonej sieci 10 ego (4039 węzłów) średni clustering wynosił aż 0.6055, co oznacza, że dwaj losowo wybrani znajomi 25 danego ego mieli ponad 60% szans, by również być znajomymi między sobą. W naszych mniejszych sieciach wartości te różnią się w zależności od sieci, ale zwykle mieszczą się w przedziale 0.5-0.6 dla największego komponentu (mniejsze komponenty, np. dwuosobowe, mają clustering równy 0 lub nieokreślony). Wysoki średni współczynnik skupienia potwierdza istnienie silnych lokalnych powiązań - w grafie występuje wiele trójkątów (grup znajomych, z których każdy zna pozostałych). Przykładowo, jeśli ego posiada grupę bliskich przyjaciół ze szkoły, to prawdopodobne jest, że większość z nich zna się nawzajem, tworząc pełne podgrafy (kliki) o dużym clusteringu. Gęstość, rozumiana jako stosunek liczby istniejących krawędzi do maksymalnej liczby krawędzi możliwej między daną liczbą wierzchołków, w ego-sieciach Facebooka jest stosunkowo niska w kategoriach bezwzględnych (co wynika z faktu, że sieci społecznościowe z natury są rzadkie). Jednak gęstość ta bywa wyższa niż w porównywalnie małych grafach generowanych losowo. Dla zobrazowania: jedna z większych ego-sieci (ID 0, 333 węzły) zawierała 5038 krawędzi, co daje gęstość ok. 0.091 (9.1%) - czyli spośród wszystkich możliwych par znajomych około 9% par faktycznie łączy relacja. W przypadku sieci 107 (1034 węzły, 26749 krawędzi) gęstość wyniosła ok. 0.05 (5%). Nasze mniejsze sieci, takie jak 3980 czy 698, mogą mieć nieco wyższe gęstości ze względu na efekt małych grup (jeśli ego ma np. 30 znajomych i wszyscy oni się znają nawzajem, to gęstość takiej małej sieci jest bardzo wysoka, bliska 100%; jednak zwykle nie każdy zna każdego, więc realnie gęstości wynoszą kilkanaście-kilkadziesiąt procent dla bardzo małych sieci i kilka procent dla większych). Ogólnie gęstość maleje wraz ze wzrostem liczby wierzchołków - większe kręgi znajomych rzadziej są kompletnie połączone. W porównaniu do grafów losowych o podobnej skali i liczbie krawędzi, ego-sieci mają wyższy clustering (krawędzie nie są rozłożone przypadkowo, lecz skoncentrowane wewnątrz grup), natomiast same wartości gęstości nie odbiegają rzędu wielkościowo - nadal są to grafy rzadkie (rzędu pojedynczych procent). Ta rzadka natura sieci społecznych jest istotna z punktu widzenia testowanych algorytmów, gdyż wiele z nich ma złożoności silnie zależne od liczby krawędzi (np. operacje przeszukiwania grafu lub znajdowania struktur klikowych mogą być szybsze w grafach rzadszych). 26 5. METODY ALGORYTMICZNE OPTYMALIZACJI KOSZTÓW LICENCJI W niniejszym rozdziale przedstawione omówione zostaną różnorodne metody algorytmiczne, które zostały wykorzystane do rozwiązywania sformułowanego w poprzednich rozdziałach problemu optymalnego zakupu licencji w sieciach społecznościowych. 5.1 Dokładne algorytmy 5.1.1 Programowanie całkowitoliczbowe Programowanie całkowitoliczbowe (ILP) to technika optymalizacji, w której dobieramy wartości zmiennych całkowitoliczbowych tak, aby zminimalizować (lub zmaksymalizować) liniową funkcję celu przy jednoczesnym spełnieniu zestawu równań i nierówności liniowych. W odróżnieniu od klasycznego programowania liniowego, ILP wymaga, aby zmienne przyjmowały wartości całkowite, co pozwala w naturalny sposób modelować decyzje typu tak/nie, włącz/wyłącz czy przydziel/nie przydziel. W zadaniu optymalnego zakupu licencji modelujemy sieć społecznościową jako graf G = (V, E), gdzie wierzchołki to użytkownicy, a krawędzie – relacje umożliwiające współdzielenie. Dla każdego użytkownika i typu licencji wprowadzamy zmienne binarne określające, kto kupuje daną licencję oraz komu ją udostępnia. Funkcję celu stanowi suma kosztów wszystkich wykupionych licencji, zaś zestaw równań i nierówności gwarantuje, że każdy użytkownik jest objęty dokładnie jedną licencją, a rozmiary grup mieszczą się w zadanych granicach. Implementacja opiera się na bibliotece pulp i solwerze CBC, który dzięki mechanizmom branch-and-bound, cutting-planes i heurystykom startowym potrafi w rozsądnym czasie znaleźć rozwiązanie optymalne dla małych i średnich grafów (rzędu kilkudziesięciu wierzchołków). Zaletą ILP jest gwarancja optymalności i elastyczność: nowe ograniczenia (np. różne modele cenowe, dodatkowe warunki zaufania czy ograniczenia sekwencyjne) można dodać poprzez kolejne zmienne lub nierówności liniowe. Główną wadą jest jednak potencjalnie nadwykładniczy czas rozwiązania w najgorszym przypadku, co sprawia, że ILP pełni tu rolę algorytmu referencyjnego dla instancji niewielkich rozmiarów. W dalszych częściach przedstawimy szczegółową konstrukcję zmiennych decyzyjnych, funkcji celu i ograniczeń, sposób rozwiązania problemu za pomocą solwera oraz metody ekstrakcji i interpretacji uzyskanego rozwiązania. Zmienne decyzyjne • xi,j,t ∈ {0, 1} dla każdej pary (i, j) takiej, że j = i lub {i, j} ∈ E, oraz każdego typu licencji 27 t ∈ {1, . . . , T}: xi,j,t = 1 ⇐⇒ użytkownik i wykupił licencję typu `t i obsługuje j. • yi,t ∈ {0, 1} dla każdego i ∈ V i t ∈ {1, . . . , T}: yi,t = 1 ⇐⇒ użytkownik i wykupił licencję typu `t. Funkcja celu Minimalizujemy łączny koszt wykupionych licencji: min X i∈V X T t=1 ct yi,t. Ograniczenia 1. Każdy użytkownik obsłużony dokładnie raz: ∀ j ∈ V : X i∈V X T t=1 xi,j,t = 1. 2. Powiązanie x z y (pojemność grupy): ∀ i ∈ V, t = 1, . . . , T : X j: {i,j}∈E∨j=i xi,j,t ≤ yi,t max t , X j: {i,j}∈E∨j=i xi,j,t ≥ yi,t min t . 3. Własny dostęp: ∀ i ∈ V, t = 1, . . . , T : xi,i,t ≥ yi,t. Rozwiązywanie i konstrukcja rozwiązania Model ILP formułowany jest za pomocą biblioteki pulp i rozwiązywany solwerem CBC. Po uzyskaniu optymalnego rozwiązania: • Dla każdej zmiennej yi,t = 1 odczytujemy grupę Si,t = { j ∈ V : xi,j,t = 1}. • Tworzymy obiekt LicenseGroup(license_type=`t, owner=i, additional_members=Si,t \ {i}). • Zestaw wszystkich grup przekazujemy do Solution(groups, total_cost, covered_nodes). Rozwiązanie oparte na ILP gwarantuje optymalne przypisanie licencji przy minimalnym koszcie i pełnym spełnieniu wszystkich ograniczeń modelu. 28 5.1.2 Algorytm naiwny Algorytm naiwny jest najbardziej bezpośrednim podejściem do problemu optymalnego przypisania licencji. Algorytm przeszukuje całą przestrzeń możliwych rozwiązań, gwarantując znalezienie globalnego optimum dla małych instancji. W przeciwieństwie do metod heurystycznych czy metaheurystycznych, które starają się jak najszybciej wygenerować dobre przybliżenie, algorytm naiwny nie stosuje żadnych uproszczeń ani aproksymacji — dla każdego możliwego podziału użytkowników na grupy licencyjne (oraz przypisania licencji indywidualnych) sprawdza warunki poprawności, oblicza łączny koszt i wybiera najlepsze rozwiązanie. Takie wyczerpujące przeszukiwanie ma jednak swoją cenę: liczba rozwiązań rośnie nadwykładniczo wraz z rozmiarem grafu, dlatego w praktyce algorytm stosuje się wyłącznie do niewielkich sieci (w niniejszej pracy — maksymalnie n ≤ 10 wierzchołków). Pomimo tej ograniczonej skalowalności, algorytm naiwny pełni kluczową rolę jako punkt odniesienia dla oceny jakości bardziej zaawansowanych metod. Jego główne zalety to prostota interpretacji, gwarancja optymalności oraz brak potrzeby dostrajania parametrów — wszystko, co jest potrzebne, to definicja dostępnych licencji i ograniczeń grupowych. Główne założenia • Rozłączność: każdy wierzchołek należy do co najwyżej jednej grupy licencyjnej. • Spójność: każda grupa indukuje spójny podgraf w G. • Pokrycie: wszystkie wierzchołki muszą być objęte licencją (indywidualną lub grupową). • Limit obliczeń: w implementacji przyjmujemy n ≤ 10 (ze względu na nadwykładniczy wzrost liczby rozwiązań). Ogólny przebieg 1. Sprawdź, czy n = |V | ≤ 10; jeśli nie, przerwij (graf zbyt duży). 2. Wygeneruj wszystkie możliwe partycje zbioru V na rozłączne podzbiory (grupy) metodą rekurencyjną. 3. Dla każdej partycji: (a) Dla każdego podzbioru (grupy) i każdego typu licencji ` ∈ L sprawdź, czy rozmiar grupy mieści się w [min`, max`]. (b) Dla każdej dopuszczalnej licencji na dany podzbiór wybierz możliwego właściciela (każdy wierzchołek w grupie) i sprawdź spójność sąsiedztwa. (c) Zbuduj przypisanie licencji do wszystkich grup w partycji. 4. Dla każdego pełnego przypisania: • Sprawdź poprawność (rozłączność, pokrycie, limity). • Oblicz koszt C. • Zaktualizuj rozwiązanie optymalne, jeśli C jest mniejsze niż dotychczasowe. 5. Jeśli żadne przypisanie nie jest poprawne, dla każdego wierzchołka przypisz najtańszą licencję indywidualną. 29 6. Zwróć najlepsze przypisanie. Generowanie przypisań 1. Partycje: rekurencyjnie generujemy wszystkie partycje Π zbioru V : Π = {P1, P2, . . . , Pk}, Pi ⊆ V, [ i Pi = V, Pi ∩ Pj = ∅. 2. Przypisania dla partycji: dla każdego Pi ∈ Π i każdego ` ∈ L takich, że min ` ≤ |Pi | ≤ max ` , oraz dla każdego możliwego wyboru właściciela v ∈ Pi sprawdzamy: Pi \ {v} ⊆ Adj(v). Jeśli ten warunek jest spełniony, tworzymy krotkę (`, v, Pi \ {v}). 3. Kombinacje: z tablicy list krotek dla każdego Pi generujemy iloczyn kartezjański — dając kompletne przypisanie dla całej partycji. Złożoność obliczeniowa Pełna przestrzeń dopuszczalnych przypisań odpowiada wszystkim rozłącznym, spójnym partycjom V z grupami o rozmiarach w [min`, max`]. Górną granicę tej przestrzeni stanowi liczba Bella: B(n) = liczba wszystkich partycji zbioru V, B(n) ∈ Θ  √ 1 n  n ln n n  . Z powodu dodatkowych ograniczeń ([min`, max`], spójność), liczba rozwiązań jest mniejsza od B(n), ale nadal rośnie nadwykładniczo. Można zatem oszacować złożoność na: O  c n  , gdzie stała c > 1 zależy od maksymalnego stopnia wierzchołków, zakresu rozmiarów licencji i limitu L odbiorców. Ze względu na tę złożoność algorytm jest praktyczny tylko dla n ≤ 10 i pełni rolę algorytmu referencyjnego. 5.1.3 Branch and Bound Wprowadzenie Branch and Bound to technika dokładnego przeszukiwania, która systematycznie eksploruje drzewo decyzyjne możliwych przydziałów licencji, jednocześnie przycinając gałęzie, dla których wiadomo, że nie przyniosą rozwiązania lepszego od już znanego. W zadaniu dystrybucji licencji w sieci społecznościowej każda decyzja o przydziale grupy licencyjnej do wierzchołka tworzy kolejny poziom drzewa. Dzięki estymacji dolnych i górnych granic kosztów dla częściowych przypisań możliwe jest szybkie odrzucanie tych gałęzi, które nie mogą doprowadzić do optymal nego rozwiązania. Założenia i przygotowanie danych • Graf G = (V, E), typy licencji L z parametrami min`, max`, c`. • Używamy struktury BranchNode, zawierającej: – częściowe przypisania assignments (mapowanie właściciel → (licencja, członkowie)), – zbiór unassigned_nodes – wierzchołków, które jeszcze nie zostały pokryte, – lower_bound – dolną granicę kosztu rozszerzenia bieżącego węzła do pełnego rozwiązania, – upper_bound – górną granicę kosztu (np. heurystyka zachłanna), – level – głębokość w drzewie decyzyjnym. • Kolejka priorytetowa sortowana po lower_bound pozwala wybierać najbardziej obiecujące węzły. • Parametr max_iterations ogranicza liczbę rozgałęzień. Ogólny przebieg 1. Inicjalizacja: • Oblicz dolną granicę dla pustych przypisań jako suma minimalnych kosztów potrzebnych do pokrycia wszystkich węzłów. • Oblicz górną granicę przez szybki algorytm zachłanny. • Utwórz węzeł początkowy (root) z pełnym zbiorem nieprzypisanych wierzchołków i dodaj go do kolejki. 2. Loop: dopóki kolejka nie jest pusta i nie przekroczono max_iterations: (a) Wyjmij węzeł o najmniejszej lower_bound. (b) Jeśli lower_bound ≥ bieżące najlepsze rozwiązanie, pomiń tę gałąź. (c) Jeśli unassigned_nodes jest puste, przekształć przypisania w pełne rozwiązanie i zaktualizuj optymalne, jeśli koszt jest niższy. (d) W przeciwnym wypadku: • Wybierz jeden wierzchołek z unassigned_nodes jako cel rozgałęzień. • Wygeneruj wszystkie możliwe przypisania licencji dla tego wierzchołka (właściciel + grupa) zgodnie z parametrami licencji i krawędziami grafu. • Dla każdego możliwego przypisania utwórz nowy węzeł z: – zaktualizowanym zbiorem assignments i unassigned_nodes, – obliczonymi nowymi lower_bound i upper_bound. • Dodaj powstałe węzły do kolejki, jeśli ich lower_bound jest mniejsze od najlepszego znanego kosztu. 3. Po zakończeniu zwróć najlepsze rozwiązanie lub – jeśli nie znaleziono – heurystykę zachłanną jako fallback. 31 Złożoność obliczeniowa W najgorszym przypadku Branch and Bound nadal może eksplorować wykładniczą liczbę węzłów. Jednak przy dobrych estymatach dolnych granic i efektywnej kolejce priorytetowej znacznie ogranicza liczbę rozgałęzień. Każde rozgałęzienie wymaga wygenerowania wszystkich możliwych grup licencyjnych dla jednego wierzchołka, co w najgorszym przypadku daje sumę kombinacji P `∈L Pmax` k=min`  d k−1  , gdzie d to stopień wierzchołka. Całkowity koszt obliczeniowy wynosi zatem w praktyce znacznie mniej niż pełne przeszukiwanie wykładnicze, ale z zachowaniem gwarancji optymalności. 5.1.4 Programowanie dynamiczne na drzewach Wprowadzenie Metoda programowania dynamicznego na drzewach (Tree DP) jest szczególną techniką optymalizacji wykorzystywaną, gdy graf wejściowy jest (lub może być zrootowany jako) drzewem. Dzięki temu zamiast eksplorować nadwykładniczą przestrzeń wszystkich podziałów, możemy w czasie wielomianowym (lub pseudo-wielomianowym przy stałym maksymalnym stopniu wierzchołków) obliczyć optymalne przypisanie licencji poprzez rekurencyjne łączenie wyników z poddrzew. Dla każdej poddrzewa liczymy minimalny koszt pokrycia wszystkich węzłów, uwzględniając różne typy licencji i możliwość objęcia przez lidera części jego potomków. Założenia i przygotowanie danych • Graf wejściowy musi być drzewem: G = (V, E) ze strukturą acykliczną. • Typy licencji L = {`1, . . . , `T } z parametrami: min ` , max ` (zakres wielkości grup), c` (koszt licencji). • Rootowanie drzewa: wybieramy dowolny węzeł jako korzeń, by zdefiniować relacje rodzic–dziecko. • Memoizacja: słownik memo[node,children] przechowuje wynik (koszt, zestaw grup) dla każdego poddrzewa. Ogólny przebieg 1. Rootowanie: wybierz dowolny węzeł jako korzeń drzewa. 2. Rekurencyjna funkcja _solve_subtree(node,parent): • Zbierz listę dzieci węzła node (sąsiedzi różni od parent). • Przypadek bazowy (liść): przypisz najtańszą licencję pojedynczą do node. • Rekurencja: dla każdego dziecka wywołaj _solve_subtree(child,node) i zapamiętaj minimalne koszty i grupy. • Wybór licencji dla node: dla każdego typu ` ∈ L i dla każdej liczby potomków k w przedziale [min` −1, min(max` −1, |children|)]: (a) Rozważ wszystkie kombinacje k dzieci do włączenia w grupę z liderem node. (b) Oblicz koszt: c` plus koszty poddrzew pozostałych dzieci (znormalne wywołania) oraz kosztów wywołania osobnego dopasowania dla włączonych dzieci (bez licen3 cji dla lidera w tych poddrzewach). (c) Zachowaj konfigurację o minimalnym łącznym koszcie i odpowiadające jej listy obiektów LicenseGroup. • Zwróć najlepszy koszt i zestaw grup dla poddrzewa z korzeniem w node. 3. Budowa rozwiązania: wywołaj _solve_subtree(root,None) i przekaż uzyskane grupy do SolutionBuilder. Złożoność obliczeniowa • Liczba stanów DP: każdy węzeł wraz ze zbiorem jego dzieci � O(n). • Dla stanu dokonujemy iteracji po T typach licencji oraz po wszystkich kombinacjach włączanych dzieci: X v∈V X T `=1 min(maxX` −1,dv) k=0  dv k  = O  n · T · 2 dmax  , gdzie dv to stopień węzła v, a dmax — maksymalny stopień w drzewie. • Jeśli maksymalny stopień dmax jest ograniczony (lub niewielki), złożoność staje się praktycznie liniowa: O(n T). Dzięki memoizacji każde poddrzewo jest rozwiązywane tylko raz, co czyni metodę znacznie szybszą niż algorytmy wykładnicze dla drzewiastych struktur grafu, z gwarancją znalezienia globalnie optymalnego rozwiązania. 5.2 Algorytmy przybliżone 5.2.1 Algorytm zachłanny Algorytmy zachłanne stanowią jedną z najprostszych i zarazem najczęściej wykorzystywanych technik przybliżonego rozwiązywania zadań kombinatorycznych, w tym problemów optymalizacyjnych na grafach. Ich kluczową ideą jest stopniowe, krokowe konstruowanie rozwiązania poprzez wybór w każdym kroku lokalnie „najlepszej” akcji — tej, która w danym momencie przynosi największą korzyść lub najmniejszy koszt. W przeciwieństwie do metod dokładnych, które eksplorują całą przestrzeń rozwiązań (jak algorytm naiwny czy ILP), heurystyki zachłanne stawiają na szybkość wykonania kosztem utraty gwarancji osiągnięcia optimum globalnego. W kontekście dystrybucji licencji w sieciach społecznościowych nasz algorytm zachłanny wykorzystuje prostą metrykę efektywności: stosunek kosztu licencji do liczby użytkowników, którym może ona zapewnić dostęp. Zaczynamy od liderów o najwyższym stopniu w grafie — oni mają największy potencjał, by obsłużyć wielu sąsiadów. Dla każdego kandydata wybieramy typ licencji o odpowiedniej pojemności tak, aby maksymalizować liczbę nowych objętych użytkowników przy minimalnym wzroście całkowitego kosztu. W efekcie uzyskujemy szybki, deterministyczny algorytm, który w praktyce dobrze sprawdza się na dużych instancjach, gdzie metody dokładne są zbyt wolne. Mimo braku formalnych gwarancji co do odległości od rozwiązania optymalnego, algorytm zachłanny ma kilka istotnych zalet. Po pierwsze, jego złożoność czasowa jest wielomianowa 3 (w praktyce bliska O(m log n) dla grafu z n wierzchołkami i m krawędziami), co pozwala go stosować nawet w przypadku dużych sieci społecznościowych. Po drugie, implementacja jest prosta, a parametry — takie jak kryterium wyboru lidera czy sposobu sortowania dostępnych sąsiadów — można łatwo dostosować do specyfiki danych. Wreszcie, algorytm zachłanny może stanowić doskonałe rozwiązanie startowe (warm start) dla bardziej zaawansowanych metaheurystyk czy solwerów ILP. Jako metoda przybliżona, algorytm zachłanny pełni ważną rolę w zestawie narzędzi do rozwiązywania problemu dystrybucji licencji: dostarcza wstępnej, szybko obliczalnej oceny kosztu optymalnego pokrycia grafu, którą można porównać z wynikiem algorytmu dokładnego lub wykorzystać jako punkt wyjścia do dalszej optymalizacji. Założenia i przygotowanie danych • Dane wejściowe: graf nieskierowany G = (V, E), lista typów licencji L ze zdefiniowanymi parametrami min ` , max ` , c` (` ∈ L). • Wstępne sortowanie: 1. Licencje malejąco według max` — by najpierw rozważać najbardziej pojemne plany. 2. Wierzchołki malejąco według stopnia deg(v) — by liderami stawały się węzły o największym potencjale obsługi. • Zmienna pomocnicza: U ⊆ V — zbiór jeszcze nieobjętych licencją wierzchołków. Ogólny przebieg 1. Faza główna: • Dla każdego węzła–lidera v w kolejności według malejącego stopnia: (a) Jeśli v ∈/ U, pomiń. (b) Wyznacz zbiór dostępnych sąsiadów N = ({v} ∪ Adj(v)) ∩ U. (c) Jeśli N = ∅, pomiń v. (d) Dla każdej licencji ` ∈ L, której |N| ≥ min`, wybierz podzbiór G` ⊆ N o rozmiarze min{|N|, max`} — np. węzły o najwyższym stopniu. (e) Oblicz efektywność e` = c`/|G`|; wybierz licencję ` ∗ o najmniejszym e`. (f) Utwórz grupę licencyjną z liderem v i dodatkowymi członkami G` ∗ \ {v}, zaktualizuj U ← U \ G` ∗ . 2. Faza uzupełniająca: Jeśli pozostały węzły w U, dla każdego u ∈ U: • Spróbuj przydzielić mu najmniejszą możliwą grupę licencyjną (według c` dla ` z |N| ≥ min`), analogicznie do fazy głównej. • Jeśli nie można, przypisz indywidualną licencję najniższego kosztu. 3. Zwróć zbudowane grupy oraz obliczony koszt sumaryczny. 34 Złożoność obliczeniowa Algorytm wymaga posortowania wierzchołków i typów licencji: O(T log T+ n log n). W fazie głównej dla każdego v iterujemy po T licencjach, sortując co najwyżej d(v) sąsiadów: X v∈V O  T + d(v)log d(v)  = O  nT + X v d(v)log n  = O  nT + m log n  , gdzie m = |E|. Faza uzupełniająca jest porównywalna. W efekcie cała procedura działa w czasie O  nT + m log n  . Jest to znacznie wydajniejsze niż wykładnicze rozwiązania dokładne, lecz nie gwarantuje optimum globalnego. 5.2.2 Algorytm dla zbioru dominującego Algorytm bazujący na koncepcji zbioru dominującego to jedna z klasycznych heurystyk przybliżonych dla problemów pokrycia wierzchołków grafu. W naszym zastosowaniu – optymalizacji zakupu licencji w sieci społecznościowej – zależy nam na wybraniu niewielkiej grupy „liderów” (użytkowników), którzy swoimi licencjami pokryją pozostałych członków sieci. Zbiór dominujący w grafie G = (V, E) to podzbiór D ⊆ V taki, że każdy wierzchołek spoza D ma sąsiada w D. W kontekście licencji oznacza to, że każdy użytkownik bez własnej licencji (odbiorca) jest sąsiadem przynajmniej jednego użytkownika z licencją grupową. Dzięki temu zamiast rozważać dowolne partycje zbioru V , wystarczy najpierw wskazać kandydatów na liderów – węzły o największym wpływie pokrycia – a dopiero następnie dobrać im konkretne plany licencyjne i członków. Metoda ta opiera się na następujących założeniach i korzyściach: 1. Redukcja przestrzeni rozwiązań. Pełne przeszukiwanie wszystkich konfiguracji jest nadwykładnicze. Wyznaczenie niewielkiego zbioru dominującego redukuje problem do doboru licencji wyłącznie dla tych węzłów oraz ich bezpośrednich sąsiadów. 2. Łatwa adaptacja do kosztów. W klasycznym zbiorze dominującym minimalizuje się karność bazując na liczebności |D|. W naszym wariancie wprowadzamy dodatkowy wymiar – koszt licencji. Heurystyka dobiera węzły do D nie tylko według liczby niepokrytych sąsiadów, ale też minimalizuje średni koszt pokrycia („koszt na osobę”), wykorzystując dostępne typy licencji i ich zakresy rozmiarów. 3. Efektywność obliczeniowa. Wyznaczenie przybliżonego zbioru dominującego metodą zachłanną (greedy) działa w czasie wielomianowym, co pozwala na skalowanie do dużych sieci (rzędu tysięcy wierzchołków). Dla każdej iteracji operujemy na stopniu wierzchołków i prostej ocenie efektywności, bez kosztownych przeglądów całych partycji. 4. Elastyczność i rozszerzalność. Algorytm można wzbogacić o dodatkowe kryteria wyboru liderów (np. wskaźniki centralności, wieloczłonowe funkcje efektywności) czy o mechanizmy poprawiające pokrycie pozostałych węzłów. Umożliwia to szybkie eksperymenty z różnymi politykami cenowymi i limitami grup. 5. Brak gwarancji optymalności globalnej. Podobnie jak większość heurystyk greedy, zbiór dominujący oparty na lokalnych wyborach nie gwarantuje znalezienia rozwiązania optymalnego. W praktyce jednak dla wielu grafów społecznościowych osiągamy wysoką jakość pokrycia przy relatywnie niskim koszcie, co czyni tę metodę wartościowym uzupełnieniem algorytmów dokładnych (ILP, algorytm naiwny) i metaheurystyk. W dalszej części opisujemy szczegóły implementacyjne: sposób wyboru dominatorów z uwzględnieniem kosztów, algorytm przydziału licencji do liderów oraz mechanizm uzupełniania pokrycia dla pozostałych wierzchołków. Krok 1: Wyznaczenie zbioru dominującego Zaczynamy od wyznaczenia zbioru dominującego D ⊆ V , który „pokrywa” wszystkie wierzchołki grafu. Wykorzystujemy tu zmodyfikowaną heurystykę zachłanną: 1. U ← V (zbiór jeszcze niepokrytych wierzchołków), D ← ∅. 2. Dopóki U 6= ∅: • Dla każdego v ∈ V \ D obliczamy zbiór potencjalnego pokrycia C(v) = {v} ∪ Adj(v)  ∩ U oraz minimalny koszt na użytkownika γ(v) = min `∈L, min`≤|C(v)|≤max` c` |C(v)| . • Wybieramy v ∗ = arg maxv  |C(v)|/γ(v)  — lidera o najlepszym stosunku pokrycia do kosztu. • D ← D ∪ {v ∗}, U ← U \ C(v ∗ ). Otrzymany zbiór D jest zbiorem dominującym o dobrej efektywności kosztowej, choć niekoniecznie minimalnym. Krok 2: Przydział licencji liderom Dla każdego dominatora v ∈ D, posortowanego malejąco według stopnia w grafie (aby najpierw obsłużyć potencjalnie największe pokrycie), dobieramy typ licencji i członków grupy w następujący sposób: 1. Zbiór dostępnych wierzchołków do obsługi: A(v) = {v} ∪ Adj(v)  ∩  V \ R  , R — zbiór już obsłużonych węzłów. 2. Dla każdej licencji ` ∈ L, której parametry min`, max` mieszczą się w 1 ≤ |A(v)| ≤ max`, wybieramy najlepszy podzbiór G` ⊆ A(v) o rozmiarze k ∈ [min`, min(|A(v)|, max`)] — np. ze wzmocnioną heurystyką wyboru najwyżej wyspecjalizowanych sąsiadów. 3. Spośród wszystkich (`, G`) wybieramy tę kombinację, która minimalizuje stosunek c`/|G`|. 4. Tworzymy obiekt LicenseGroup(license_type=`, owner=v, additional_members=G`\{v}), a następnie aktualizujemy R ← R ∪ G`. Krok 3: Pokrycie pozostałych wierzchołków Po obsłużeniu wszystkich dominatorów mogą pozostać niepokryte wierzchołki V \R. Postępujemy podobnie jak w kroku 2, ale liderami stają się teraz dowolne niepokryte węzły, a w ostateczności przypisujemy im najtańszą licencję indywidualną, jeśli żaden plan grupowy nie jest dopasowany do ich sąsiedztwa. Zalety i ograniczenia Algorytm zbioru dominującego łączy niewielką złożoność heurystyki dominacji rzymskiej z prostym doborem licencji, co skutkuje: • Szybkością wykonania — złożoność w przybliżeniu O(n 2T) dla grafu n wierzchołków i T typów licencji. • Łatwością rozszerzeń — można wprowadzić dodatkowe kryteria wyboru dominatorów lub bardziej zaawansowane metryki efektywności. Jednocześnie brak gwarancji osiągnięcia globalnego optimum oraz możliwa duża przewaga kosztu nad rozwiązaniem referencyjnym (ILP lub naiwnym) stanowią główne ograniczenia tej metody. 5.2.3 Algorytm losowy Algorytm losowy (ang. randomized) łączy w sobie cechy strategii zachłannej z elementem nieprzewidywalności, co pozwala na generowanie zróżnicowanych rozwiązań w krótkim czasie. W kontekście dystrybucji licencji w sieci społecznościowej celem jest otrzymanie przyzwoitej jakości rozwiązania szybciej niż w przypadku metod dokładnych (ILP, algorytm naiwny), a jednocześnie uniknięcie pułapek najprostszej heurystyki zachłannej, która może utknąć w lokalnym optimum. Główna idea Algorytm działa na przemian w dwóch trybach: • zachłannym – wybiera lidera i typ licencji o najlepszym stosunku kosztu do liczby objętych użytkowników, • losowym – losowo dobiera typ licencji oraz członków grupy w dopuszczalnych granicach, dzięki czemu niektóre decyzje mogą być nietrywialne i odkrywać inne obszary przestrzeni rozwiązań. Przełączanie między trybami odbywa się z zadanym prawdopodobieństwem pgreedy – typowo większym od 0.5, aby zachować równowagę między eksploracją a eksploatacją. Przebieg algorytmu 1. Jeśli graf jest pusty, zwróć rozwiązanie puste. 2. Ustaw ziarno generatora losowego dla powtarzalności (jeśli podano). 3. Utwórz listę wierzchołków, wykonaj losowe przemieszanie, oraz zbiór niepokrytych węzłów U = V . 4. Dla każdego wierzchołka v w losowej kolejności: 37 • Jeśli v ∈/ U, pomiń. • Wylosuj liczbę r ∈ [0, 1); jeśli r < pgreedy, użyj strategii zachłannej, w przeciwnym razie strategii losowej. • Uzyskaj przypisanie (`, S): typ licencji ` i grupa S ⊆ U zawierająca v. • Jeśli przypisanie jest prawidłowe (spełnia minimalne i maksymalne pojemności oraz spójność), dodaj nową grupę, zaktualizuj U ← U \ S. 5. Po przejściu wszystkich wierzchołków, jeśli pozostały niepokryte U 6= ∅, dla każdego u ∈ U przypisz najtańszą licencję pojedynczą. 6. Zbuduj i zwróć obiekt Solution zawierający utworzone grupy, sumaryczny koszt oraz pokryte węzły. Zalety i wady Algorytm losowy oferuje: • Zróżnicowanie rozwiązań: dzięki elementowi losowemu unika stagnacji w jednym kierunku eksploracji, • Elastyczność: parametr pgreedy można dostosować do pożądanego balansu między szybkością a jakością, • Prosta implementacja: opiera się na istniejących funkcjach zachłannej i losowej alokacji licencji. Jednocześnie: • brak gwarancji jakości globalnej – wyniki różnią się między kolejnymi uruchomieniami, • konieczność doboru parametru pgreedy i ziarna, co wymaga eksperymentów dla konkretnych danych. 5.3 Metaheurystyki 5.3.1 Algorytm genetyczny • Ewolucyjna optymalizacja z krzyżowaniem i mutacją • Eksploracja przestrzeni rozwiązań • Dostosowany do struktury problemu dominacji 5.3.2 Tabu Search Wprowadzenie Tabu Search to metaheurystyka, która rozszerza klasyczne lokalne przeszukiwanie o mechanizm „tabu” zapobiegający powrotom do niedawnych stanów rozwiązania. W zadaniu dystrybucji licencji w sieci społecznościowej celem jest minimalizacja łącznego kosztu przy jednoczesnym spełnieniu ograniczeń spójności i rozmiaru grup. Tabu Search pozwala na uniknięcie stagnacji w lokalnych minimach, co jest częstym problemem prostych heurystyk zachłannych. Założenia i przygotowanie danych • Rozwiązanie startowe generowane jest przez algorytm zachłanny, zapewniający dobry punkt wyjścia. 38 • Tabu lista służy przechowywaniu identyfikatorów ostatnio odwiedzanych rozwiązań, by unikać cykli. • Parametry: – max_iterations – maksymalna liczba iteracji, – tabu_tenure – długość tabu listy (liczba przechowywanych wpisów). Ogólny przebieg 1. Rozpocznij od rozwiązania zachłannego Scurrent; ustaw Sbest = Scurrent, tabu listę pustą. 2. Dla każdej z maksymalnie max_iterations rund: (a) Wygeneruj zbiór sąsiadów N(Scurrent) przez losowe mutacje (np. przeniesienie węzła między grupami, zamiana lidera). (b) Spośród sąsiadów wybierz Scandidate o najmniejszym koszcie, który nie jest na tabu liście lub poprawia globalne optimum (kryterium aspiracji). (c) Jeśli brak dopuszczalnych sąsiadów, przerwij pętlę. (d) Ustaw Scurrent = Scandidate. (e) Jeśli koszt Scurrent jest niższy niż koszt Sbest, zaktualizuj Sbest = Scurrent. (f) Dodaj identyfikator Scurrent do tabu listy; jeśli lista przekroczy tabu_tenure, usuń najstarszy wpis. 3. Zwróć Sbest jako rozwiązanie końcowe. Złożoność obliczeniowa W każdej iteracji generujemy stałą liczbę sąsiadów (k mutacji) i dla każdego oceniamy koszt w czasie O(C) (walidacja i sumowanie kosztów). Dla max_iterations iteracji całkowity koszt to O  max_iterations × k × C  . W praktyce dobiera się niewielkie k i umiarkowane max_iterations, co pozwala uzyskać znacznie szybsze działanie niż w metodach dokładnych, przy jednoczesnym uniknięciu pułapek lokalnych minimów charakterystycznych dla prostych heurystyk. 5.3.3 Algorytm mrówkowy Wprowadzenie Algorytm mrówkowy (Ant Colony Optimization, ACO) to metaheurystyka inspirowana zachowaniem kolonii mrówek, które komunikują się za pomocą feromonów. W zadaniu dystrybucji licencji modelujemy każdy ruch mrówki jako budowanie rozwiązania – wyboru lidera, typu licencji i grupy odbiorców. Feromony gromadzone na elementach rozwiązania (połączeniach między węzłami oraz przypisaniach typu licencji) kierują kolejnych „mrówek” ku bardziej obiecującym fragmentom przestrzeni rozwiązań, pozwalając łączyć eksplorację i eksploatację. Założenia i przygotowanie danych • Graf reprezentujący użytkowników i ich relacje: G = (V, E), gdzie V to węzły (użytkownicy), a E – krawędzie (możliwość współdzielenia licencji). 3 • Typy licencji L = {`1, . . . , `T } z parametrami min`, max`, c`. • Tablica feromonów: dla każdej pary węzeł–licencja (v, `) oraz dla każdej krawędzi (u, v) z licencją ` przechowujemy wartość feromonu τ . • Macierz heurystyk: ocena jakości lokalnego wyboru, np. odwrotność kosztu lub stopień węzła. • Parametry metaheurystyki: – α – wpływ feromonów na decyzje mrówek, – β – wpływ informacji heurystycznej, – ρ – współczynnik parowania feromonów (evaporation rate), – q0 – próg eksploracji vs. eksploatacji (prawdopodobieństwo wyboru najwyższego współczynnika), – m – liczba mrówek w kolonii, – I – maksymalna liczba iteracji. Ogólny przebieg 1. Inicjalizacja: feromony τ0 ustawiamy na stałą wartość, heurystyki obliczamy raz na podstawie parametrów licencji i stopni węzłów. 2. Rozwiązanie początkowe: generujemy losową konfigurację licencji lub wykorzystujemy prostą heurystykę. 3. Iteracje mrówek (do I): (a) Każda z m mrówek wznawia od pustego pokrycia i kolejno: • Wybiera węzeł–lidera v spośród niepokrytych, korzystając z kombinacji feromonów i heurystyk: P(v) ∝  τ (v, `) α [η(v, `)]β . • Dla wybranego ` ∈ L i lidera v dobiera kolejnych członków grupy w podobny sposób, aż do osiągnięcia max` lub wyczerpania kandydatów. • Zapisuje powstałą grupę i usuwa pokryte węzły. (b) Po zbudowaniu pełnego rozwiązania wykonuje się opcjonalne przeszukiwanie lokalne (np. drobna zamiana licencji w grupach poprawiająca koszt). (c) Parowanie feromonów: dla każdego klucza feromonowego (v, `) i każdej pary (u, v, `) zmniejszamy wartość o czynnik (1−ρ), a następnie dodajemy porcję zależną od jakości najlepszego rozwiązania: τ ← (1 − ρ) τ + ∆τ, ∆τ ∝ 1 koszt_best. (d) Resetujemy licznik braku poprawy, ewentualnie przerywamy, jeśli osiągnięto limit kolejnych iteracji bez ulepszenia. 4. Zakończenie: zwracamy najlepsze rozwiązanie znalezione przez mrówki. 40 Złożoność obliczeniowa Każda iteracja składa się z konstrukcji m rozwiązań – budowania grup przez sekwencyjny wybór liderów i członków, co w najgorszym przypadku wymaga O(nT) operacji na węźle. Parowanie feromonów to kolejna operacja O(nT + mT). Dla I iteracji daje to łącznie O  I × m × (nT + mT)  . W praktyce parametry m i I dobiera się tak, aby proces był wykonalny czasowo, a jednocześnie pozwalał na zróżnicowaną eksplorację przestrzeni rozwiązań i zbieranie informacji zwrotnych za pomocą feromonów. Metoda ACO łączy zalety losowości i ukierunkowania feromonami, często osiągając dobre wyniki kosztowe przy akceptowalnym czasie obliczeń. 5.3.4 Symulowane wyżarzanie (Simulated Annealing) Wprowadzenie Symulowane wyżarzanie to metaheurystyka inspirowana procesem termodynamicznym wyżarzania metali, w którym materiał jest podgrzewany, a następnie powoli schładzany, by osiągnąć konfigurację o minimalnej energii. W optymalizacji combinatorycznej analogią energii jest wartość funkcji celu (koszt licencji), a temperatura kontroluje prawdopodobieństwo akceptacji gorszych rozwiązań, co pozwala na uwolnienie się z lokalnych minimów. W zadaniu dystrybucji licencji algorytm zaczyna od dobrego przybliżenia (heurystyka zachłanna), po czym w kolejnych krokach generuje sąsiednie rozwiązania przez niewielkie perturbacje (mutacje). Zmiana rozwiązania jest akceptowana zawsze, gdy prowadzi do obniżenia kosztu, a w przeciwnym wypadku z prawdopodobieństwem zależnym od różnicy kosztów i bieżącej temperatury. Temperatura stopniowo spada według założonego współczynnika schładzania, zmniejszając liczbę akceptowanych ruchów „w górę”, aż do stabilizacji w okolicy dobrego minimum. Założenia i parametry Algorytm wymaga następujących parametrów: • T0 – temperatura początkowa (np. 100), • α – współczynnik schładzania (0 < α < 1, np. 0.995), • Tmin – minimalna temperatura, przy której kończymy (∼ 10−3 ), • Imax – maksymalna liczba iteracji (np. 20 000), • Smax – maksymalna liczba kolejnych kroków bez akceptacji poprawy (stall limit, np. 2 000). Do generowania sąsiadów wykorzystujemy zbiór operatorów mutacji: zmiana typu licencji, przeniesienie członka między grupami, zamianę członków, łączenie i dzielenie grup. Ogólny przebieg 1. Inicjalizacja: • Rozwiązanie startowe S uzyskane heurystyką zachłanną; gdy jest niepoprawne, fallback do przydziału indywidualnego. • Ustaw temperaturę T ← T0, najlepsze rozwiązanie Sbest ← S, licznik stagnacji s ← 0. 2. Pętla iteracyjna (do Imax): (a) Wygeneruj sąsiada S 0 przez losowy wybór jednego z operatorów mutacji; jeśli nie moż4 na, zwiększ s. (b) Oblicz różnicę kosztów ∆ = cost(S 0 ) − cost(S). (c) Jeśli ∆ < 0 lub exp(−∆/T) > rand(0, 1), zaakceptuj przejście: S ← S 0 , zresetuj s jeśli koszt się poprawił i zaktualizuj Sbest. (d) Inaczej: inkrementuj s. (e) Jeśli s ≥ Smax, zmniejsz temperaturę dwukrotnie: T ← max(Tmin, T/2), ustaw s ← 0. (f) Schłodź: T ← T · α. Jeśli T < Tmin, przerwij. 3. Zakończenie: zwróć Sbest jako najlepsze znalezione rozwiązanie. Złożoność obliczeniowa Każda iteracja wymaga próby kilku mutacji i oceny kosztu sąsiedniego rozwiązania (walidacja + sumowanie), co zajmuje O(C), gdzie C to koszt jednej walidacji. Dla Imax iteracji i maksymalnie M prób mutacji na krok otrzymujemy złożoność O  Imax × M × C  . Dzięki stopniowemu obniżaniu temperatury i limitowi stagnacji algorytm jest w stanie skupić się na obszarach obiecujących, zapewniając dobry kompromis między jakością rozwiązania a czasem obliczeń. 4 6. EKSPERYMENTY I ANALIZA WYNIKÓW Niniejszy rozdział przedstawia szczegółowe wyniki eksperymentów mających na celu ocenę jakości i efektywności opracowanych algorytmów optymalizacji zakupu licencji oprogramowania w grafowych modelach sieci społecznościowych. Analiza została przeprowadzona z wykorzystaniem różnorodnych danych testowych opisanych w poprzednim rozdziale, zarówno rzeczywistych, jak i syntetycznych. Algorytmy były oceniane pod kątem jakości uzyskiwanych rozwiązań, szybkości działania oraz odporności na zmiany parametrów sieci. 6.1 Kryteria oceny • Definicja metryk użytych do oceny: – średni stosunek kosztu, – średnie przyspieszenie, – średni koszt, – średni czas [ms], – średni koszt ILP, – średni czas ILP, – liczność próby. • Uzasadnienie wyboru kryteriów. 6.2 Środowisko testowe • Parametry sprzętowe (procesor, liczba rdzeni, RAM, system operacyjny). • Użyte narzędzia i biblioteki (np. Python, networkx, graph_visualizer). • Sposób uruchamiania eksperymentów (powtarzalność, kontrola losowości). 6.3 Eksperymenty 6.3.1 Eksperymenty na grafach rzeczywistych • Opis danych wejściowych (pochodzenie, rozmiar, charakterystyka). • Wyniki i ich analiza (tabele, wykresy, omówienie). • Wnioski cząstkowe. 6.3.2 Eksperymenty na grafach syntetycznych • Sposób generowania danych testowych. • Wyniki i ich analiza (tabele, wykresy, omówienie). • Wnioski cząstkowe. 43 6.4 Wpływ parametrów na efektywność algorytmów • Analiza wpływu hiperparametrów (np. temperatura początkowa, tempo chłodzenia, liczba iteracji). • Porównanie różnych ustawień parametrów. • Dyskusja kompromisów między kosztem a czasem obliczeń. 44 WYKAZ LITERATURY 1. The Subscription Economy Index. [B.d.]. Dostępne także z: https : / / www . amic . media / media/files/file_352_2844.pdf. 2. [B.d.]. Dostępne także z: https : / / www . juniperresearch . com / research / fintech - payments/ecommerce/subscription-economy-market-report/. 3. DUOLINGO. Rodzina – Słownictwo w Duolingo. 2025. Dostępne także z: https : / / pl . duolingo.com/family. Dostęp: 12 czerwca 2025. 4. BRANDES, Ulrik; WAGNER, Dorothea. Analysis and Visualization of Social Networks. W: Graph Drawing Software. Red. JÜNGER, Michael; MUTZEL, Petra. Berlin, Heidelberg: Springer Berlin Heidelberg, 2004, s. 321–340. ISBN 978-3-642-18638-7. Dostępne z DOI: 10 . 1007/978-3-642-18638-7_15. 5. NETTLETON, David F. Data mining of social networks represented as graphs. Computer Science Review. 2013, t. 7, s. 1–34. ISSN 1574-0137. Dostępne z DOI: https://doi.org/ 10.1016/j.cosrev.2012.12.001. 6. HAYNES, Teresa W.; HEDETNIEMI, Stephen T.; SLATER, Peter J. Fundamentals of Domination in Graphs. New York: Marcel Dekker, 1998. ISBN 0-8247-0033-3. Dostępne z DOI: 10.1201/9781482246582. 7. WIKIPEDIA CONTRIBUTORS. Dominating set — Wikipedia, The Free Encyclopedia [https: / / en . wikipedia . org / wiki / Dominating _ set]. 2024. Dostępne także z: https : / / en . wikipedia.org/wiki/Dominating_set. Dostęp: 14 czerwca 2025. 8. POUREIDI, Abolfazl; FATHALI, Jafar. Algorithmic results in Roman dominating functions on graphs. Information Processing Letters. 2023, t. 182, s. 106363. ISSN 0020-0190. Dostępne z DOI: https://doi.org/10.1016/j.ipl.2023.106363. 9. PANDA, B.S.; GOYAL, Pooja. Hardness results of global roman domination in graphs. Discrete Applied Mathematics. 2023, t. 341, s. 337–348. ISSN 0166-218X. Dostępne z DOI: https://doi.org/10.1016/j.dam.2023.08.020. 10. ALIMONTI, Paola; KANN, Viggo. Some APX-completeness results for cubic graphs. Theoretical Computer Science. 2000, t. 237, nr. 1, s. 123–134. ISSN 0304-3975. Dostępne z DOI: https://doi.org/10.1016/S0304-3975(98)00158-3. 11. BERMAN, Piotr; FUJITO, Toshihiro. On Approximation Properties of the Independent Set Problem for Low Degree Graphs. Theory Comput. Syst. 1999, t. 32, s. 115–132. Dostępne z DOI: 10.1007/s002240000113. 12. FAVARON, Odile; KARAMI, Hosein; KHOEILAR, R.; SHEIKHOLESLAMI, Seyed. On the Roman domination number of a graph. Discrete Mathematics. 2009, t. 309, s. 3447–3451. Dostępne z DOI: 10.1016/j.disc.2008.09.043. 45 13. COCKAYNE, Ernie; DREYER, Paul; HEDETNIEMI, Sandra; HEDETNIEMI, Stephen. Roman domination in graphs. Discrete Mathematics. 2004, t. 278, s. 11–22. Dostępne z DOI: 10.1016/j.disc.2003.06.004. 14. CHAUDHARY, Juhi; PRADHAN, Dinabandhu. Roman 3-domination in graphs: Complexity and algorithms. Discrete Applied Mathematics. 2024, t. 354, s. 301–325. ISSN 0166- -218X. Dostępne z DOI: https : / / doi . org / 10 . 1016 / j . dam . 2022 . 09 . 017. 18th Cologne-Twente Workshop on Graphs and Combinatorial Optimization (CTW 2020). 15. GHAFFARI-HADIGHEH, Alireza. Roman domination problem with uncertain positioning and deployment costs. Soft Computing. 2020, t. 24. Dostępne z DOI: 10.1007/s00500-019- 03811-z. 16. BOOTH, K. S. Dominating Sets in Chordal Graphs. 1980. Research Report, CS-80-34. University of Waterloo, Department of Computer Science. Includes a reduction from Vertex Cover to Dominating Set, establishing NP-completeness. 17. CHAMBERS, Erin W.; KINNERSLEY, Bill; PRINCE, Noah; WEST, Douglas B. Extremal problems for Roman domination. SIAM Journal on Discrete Mathematics. 2009, t. 23, nr. 3, s. 1575–1586. Dostępne z DOI: 10.1137/070699688. 18. KUHN, Fabian. Network Algorithms – Summer Term 2012 [Lecture notes, Albert-Ludwigs- -Universität Freiburg]. 2012. [term. wiz. 2025-06-30]. Dostępne z: https://ac.informatik. uni - freiburg . de / teaching / ss _ 12 / network - algorithms . php. Course web page and lecture notes. 19. PARRA INZA, Ernesto; VAKHANIA, Nodari; SIGARRETA ALMIRA, José María; HERNÁNDEZ MIRA, Frank Angel. Exact and heuristic algorithms for the domination problem. European Journal of Operational Research. 2024, t. 313, nr. 3, s. 926–936. ISSN 0377-2217. Dostępne z DOI: https://doi.org/10.1016/j.ejor.2023.08.033. 20. ERDŐS, Paul; RÉNYI, Alfréd. On the evolution of random graphs. Publications of the Mathematical Institute of the Hungarian Academy of Sciences. 1960, t. 5, s. 17–61. 21. BARABÁSI, Albert-László; ALBERT, Réka. Emergence of scaling in random networks. Science. 1999, t. 286, nr. 5439, s. 509–512. 22. WATTS, Duncan J.; STROGATZ, Steven H. Collective dynamics of ‘small-world’ networks. Nature. 1998, t. 393, nr. 6684, s. 440–442. Dostępne z DOI: 10.1038/30918. 46